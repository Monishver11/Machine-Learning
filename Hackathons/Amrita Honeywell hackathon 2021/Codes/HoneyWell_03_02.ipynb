{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nnj7LlhpT6if"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k2noszNMUvk_"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from keras.layers import Dense,BatchNormalization,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import regularizers\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYyPEGzcUvoS"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'Voltage_L1_DataSet1.csv')\n",
    "df2 = pd.read_csv(r'Voltage_L1_DataSet2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dohbhr9BUvrt"
   },
   "outputs": [],
   "source": [
    "df1.columns = np.arange(len(df1.columns))\n",
    "df2.columns = np.arange(len(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Gx0ZrV_sUvxr",
    "outputId": "2fd20077-b9c8-4d5a-d21f-0e428746c9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5999, 128)\n",
      "(5999, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-797.962914</td>\n",
       "      <td>-1320.199586</td>\n",
       "      <td>-1828.741445</td>\n",
       "      <td>-2319.935857</td>\n",
       "      <td>-2789.218649</td>\n",
       "      <td>-3231.111864</td>\n",
       "      <td>-3641.962908</td>\n",
       "      <td>-4018.119193</td>\n",
       "      <td>-4355.929647</td>\n",
       "      <td>-4650.829055</td>\n",
       "      <td>-4904.643864</td>\n",
       "      <td>-5107.330184</td>\n",
       "      <td>-5261.626825</td>\n",
       "      <td>-5366.622879</td>\n",
       "      <td>-5418.663525</td>\n",
       "      <td>-5419.576973</td>\n",
       "      <td>-5367.535249</td>\n",
       "      <td>-5264.365732</td>\n",
       "      <td>-5110.069166</td>\n",
       "      <td>-4906.470001</td>\n",
       "      <td>-4656.307539</td>\n",
       "      <td>-4364.146538</td>\n",
       "      <td>-4024.510575</td>\n",
       "      <td>-3650.179436</td>\n",
       "      <td>-3239.328934</td>\n",
       "      <td>-2797.436518</td>\n",
       "      <td>-2329.066729</td>\n",
       "      <td>-1837.871278</td>\n",
       "      <td>-1329.329968</td>\n",
       "      <td>-808.005760</td>\n",
       "      <td>-278.465093</td>\n",
       "      <td>252.902023</td>\n",
       "      <td>782.442935</td>\n",
       "      <td>1303.766529</td>\n",
       "      <td>1812.308746</td>\n",
       "      <td>2303.502822</td>\n",
       "      <td>2772.785644</td>\n",
       "      <td>3215.592255</td>\n",
       "      <td>3626.442570</td>\n",
       "      <td>4002.599102</td>\n",
       "      <td>...</td>\n",
       "      <td>-3239.328487</td>\n",
       "      <td>-2797.435948</td>\n",
       "      <td>-2329.066521</td>\n",
       "      <td>-1837.871910</td>\n",
       "      <td>-1329.329479</td>\n",
       "      <td>-808.005477</td>\n",
       "      <td>-279.377475</td>\n",
       "      <td>252.901869</td>\n",
       "      <td>781.530215</td>\n",
       "      <td>1303.767033</td>\n",
       "      <td>1812.308177</td>\n",
       "      <td>2304.416161</td>\n",
       "      <td>2773.699506</td>\n",
       "      <td>3215.591849</td>\n",
       "      <td>3627.355635</td>\n",
       "      <td>4002.598697</td>\n",
       "      <td>4340.409797</td>\n",
       "      <td>4635.308762</td>\n",
       "      <td>4889.123899</td>\n",
       "      <td>5091.809794</td>\n",
       "      <td>5246.107486</td>\n",
       "      <td>5351.102295</td>\n",
       "      <td>5403.143675</td>\n",
       "      <td>5403.143732</td>\n",
       "      <td>5351.102775</td>\n",
       "      <td>5247.932927</td>\n",
       "      <td>5093.636278</td>\n",
       "      <td>4889.123913</td>\n",
       "      <td>4639.874673</td>\n",
       "      <td>4346.800923</td>\n",
       "      <td>4008.077109</td>\n",
       "      <td>3632.834002</td>\n",
       "      <td>3221.982426</td>\n",
       "      <td>2780.090228</td>\n",
       "      <td>2311.720161</td>\n",
       "      <td>1821.438861</td>\n",
       "      <td>1311.983509</td>\n",
       "      <td>790.659456</td>\n",
       "      <td>262.031836</td>\n",
       "      <td>-269.335205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4387.885674</td>\n",
       "      <td>4567.747164</td>\n",
       "      <td>4693.741356</td>\n",
       "      <td>4776.824895</td>\n",
       "      <td>4824.300958</td>\n",
       "      <td>4850.777519</td>\n",
       "      <td>4862.646175</td>\n",
       "      <td>4867.211521</td>\n",
       "      <td>4866.298624</td>\n",
       "      <td>4858.081691</td>\n",
       "      <td>4839.821272</td>\n",
       "      <td>4801.475225</td>\n",
       "      <td>4735.739730</td>\n",
       "      <td>4633.482680</td>\n",
       "      <td>4480.098867</td>\n",
       "      <td>4263.717062</td>\n",
       "      <td>3982.513234</td>\n",
       "      <td>3625.529989</td>\n",
       "      <td>3194.592586</td>\n",
       "      <td>2690.615580</td>\n",
       "      <td>2121.815686</td>\n",
       "      <td>1499.149171</td>\n",
       "      <td>836.309474</td>\n",
       "      <td>150.645858</td>\n",
       "      <td>-539.583464</td>\n",
       "      <td>-1214.291896</td>\n",
       "      <td>-1857.957949</td>\n",
       "      <td>-2453.234297</td>\n",
       "      <td>-2987.340713</td>\n",
       "      <td>-3452.058138</td>\n",
       "      <td>-3842.822995</td>\n",
       "      <td>-4158.721282</td>\n",
       "      <td>-4403.405653</td>\n",
       "      <td>-4583.267220</td>\n",
       "      <td>-4709.261054</td>\n",
       "      <td>-4793.257930</td>\n",
       "      <td>-4839.820962</td>\n",
       "      <td>-4866.297128</td>\n",
       "      <td>-4879.079514</td>\n",
       "      <td>-4882.731612</td>\n",
       "      <td>...</td>\n",
       "      <td>-542.322021</td>\n",
       "      <td>-1217.030331</td>\n",
       "      <td>-1860.696745</td>\n",
       "      <td>-2455.060932</td>\n",
       "      <td>-2989.166228</td>\n",
       "      <td>-3453.883859</td>\n",
       "      <td>-3844.648379</td>\n",
       "      <td>-4159.634438</td>\n",
       "      <td>-4404.318373</td>\n",
       "      <td>-4583.266716</td>\n",
       "      <td>-4709.261622</td>\n",
       "      <td>-4793.257592</td>\n",
       "      <td>-4839.820102</td>\n",
       "      <td>-4866.297534</td>\n",
       "      <td>-4879.079451</td>\n",
       "      <td>-4882.732017</td>\n",
       "      <td>-4881.818474</td>\n",
       "      <td>-4873.601984</td>\n",
       "      <td>-4855.341237</td>\n",
       "      <td>-4817.908616</td>\n",
       "      <td>-4751.259069</td>\n",
       "      <td>-4649.003265</td>\n",
       "      <td>-4496.531718</td>\n",
       "      <td>-4279.237302</td>\n",
       "      <td>-3998.032706</td>\n",
       "      <td>-3641.049793</td>\n",
       "      <td>-3210.112473</td>\n",
       "      <td>-2706.135664</td>\n",
       "      <td>-2137.335549</td>\n",
       "      <td>-1514.668783</td>\n",
       "      <td>-850.916937</td>\n",
       "      <td>-165.252287</td>\n",
       "      <td>524.062959</td>\n",
       "      <td>1199.684611</td>\n",
       "      <td>1842.437384</td>\n",
       "      <td>2437.714882</td>\n",
       "      <td>2972.733259</td>\n",
       "      <td>3437.450839</td>\n",
       "      <td>3828.215741</td>\n",
       "      <td>4143.201102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4050.074299</td>\n",
       "      <td>-4340.408587</td>\n",
       "      <td>-4576.875995</td>\n",
       "      <td>-4769.518913</td>\n",
       "      <td>-4918.338175</td>\n",
       "      <td>-5025.159834</td>\n",
       "      <td>-5100.026323</td>\n",
       "      <td>-5141.111052</td>\n",
       "      <td>-5153.892968</td>\n",
       "      <td>-5137.458861</td>\n",
       "      <td>-5091.809174</td>\n",
       "      <td>-5014.204029</td>\n",
       "      <td>-4900.078226</td>\n",
       "      <td>-4746.694853</td>\n",
       "      <td>-4552.225090</td>\n",
       "      <td>-4306.628130</td>\n",
       "      <td>-4008.988999</td>\n",
       "      <td>-3659.309075</td>\n",
       "      <td>-3255.763095</td>\n",
       "      <td>-2801.088514</td>\n",
       "      <td>-2298.024633</td>\n",
       "      <td>-1753.875216</td>\n",
       "      <td>-1176.858860</td>\n",
       "      <td>-577.929348</td>\n",
       "      <td>31.955483</td>\n",
       "      <td>640.927176</td>\n",
       "      <td>1237.117177</td>\n",
       "      <td>1809.569762</td>\n",
       "      <td>2349.153124</td>\n",
       "      <td>2845.826291</td>\n",
       "      <td>3295.022824</td>\n",
       "      <td>3691.265717</td>\n",
       "      <td>4034.554320</td>\n",
       "      <td>4323.975530</td>\n",
       "      <td>4561.356298</td>\n",
       "      <td>4753.998880</td>\n",
       "      <td>4902.818171</td>\n",
       "      <td>5009.640226</td>\n",
       "      <td>5084.505985</td>\n",
       "      <td>5125.590961</td>\n",
       "      <td>...</td>\n",
       "      <td>30.129927</td>\n",
       "      <td>640.014744</td>\n",
       "      <td>1236.204383</td>\n",
       "      <td>1808.656128</td>\n",
       "      <td>2348.240611</td>\n",
       "      <td>2844.913572</td>\n",
       "      <td>3294.110443</td>\n",
       "      <td>3691.265562</td>\n",
       "      <td>4033.641600</td>\n",
       "      <td>4323.976034</td>\n",
       "      <td>4561.355729</td>\n",
       "      <td>4753.999218</td>\n",
       "      <td>4902.819032</td>\n",
       "      <td>5009.639820</td>\n",
       "      <td>5083.593047</td>\n",
       "      <td>5125.590557</td>\n",
       "      <td>5138.373119</td>\n",
       "      <td>5121.938568</td>\n",
       "      <td>5076.289209</td>\n",
       "      <td>4998.683639</td>\n",
       "      <td>4884.558887</td>\n",
       "      <td>4730.261267</td>\n",
       "      <td>4536.705240</td>\n",
       "      <td>4291.107890</td>\n",
       "      <td>3993.469527</td>\n",
       "      <td>3643.789270</td>\n",
       "      <td>3240.243209</td>\n",
       "      <td>2784.655428</td>\n",
       "      <td>2281.591768</td>\n",
       "      <td>1738.355604</td>\n",
       "      <td>1161.338395</td>\n",
       "      <td>563.322919</td>\n",
       "      <td>-47.475988</td>\n",
       "      <td>-656.447463</td>\n",
       "      <td>-1252.637741</td>\n",
       "      <td>-1825.089177</td>\n",
       "      <td>-2364.673580</td>\n",
       "      <td>-2861.346591</td>\n",
       "      <td>-3309.630078</td>\n",
       "      <td>-3706.785897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3458.450134</td>\n",
       "      <td>3686.700705</td>\n",
       "      <td>4000.773209</td>\n",
       "      <td>4392.451258</td>\n",
       "      <td>4834.343975</td>\n",
       "      <td>5269.845213</td>\n",
       "      <td>5636.871457</td>\n",
       "      <td>5876.078192</td>\n",
       "      <td>5950.944421</td>\n",
       "      <td>5841.384319</td>\n",
       "      <td>5574.787489</td>\n",
       "      <td>5187.674864</td>\n",
       "      <td>4745.782747</td>\n",
       "      <td>4310.280145</td>\n",
       "      <td>3932.297960</td>\n",
       "      <td>3637.398025</td>\n",
       "      <td>3422.843307</td>\n",
       "      <td>3256.677378</td>\n",
       "      <td>3089.597412</td>\n",
       "      <td>2864.998869</td>\n",
       "      <td>2526.275355</td>\n",
       "      <td>2051.515086</td>\n",
       "      <td>1433.412463</td>\n",
       "      <td>704.837776</td>\n",
       "      <td>-84.908711</td>\n",
       "      <td>-866.438320</td>\n",
       "      <td>-1578.579486</td>\n",
       "      <td>-2169.290827</td>\n",
       "      <td>-2616.662099</td>\n",
       "      <td>-2928.908272</td>\n",
       "      <td>-3138.898830</td>\n",
       "      <td>-3303.238866</td>\n",
       "      <td>-3473.970114</td>\n",
       "      <td>-3702.220761</td>\n",
       "      <td>-4015.379905</td>\n",
       "      <td>-4406.145289</td>\n",
       "      <td>-4848.037975</td>\n",
       "      <td>-5283.538819</td>\n",
       "      <td>-5651.478793</td>\n",
       "      <td>-5891.598282</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.995262</td>\n",
       "      <td>-865.524749</td>\n",
       "      <td>-1577.666277</td>\n",
       "      <td>-2169.291459</td>\n",
       "      <td>-2617.574612</td>\n",
       "      <td>-2928.907989</td>\n",
       "      <td>-3138.898210</td>\n",
       "      <td>-3303.239020</td>\n",
       "      <td>-3473.969832</td>\n",
       "      <td>-3702.220257</td>\n",
       "      <td>-4015.380473</td>\n",
       "      <td>-4407.057953</td>\n",
       "      <td>-4848.037115</td>\n",
       "      <td>-5283.539225</td>\n",
       "      <td>-5650.565728</td>\n",
       "      <td>-5890.685686</td>\n",
       "      <td>-5966.464270</td>\n",
       "      <td>-5857.817614</td>\n",
       "      <td>-5592.133458</td>\n",
       "      <td>-5205.021257</td>\n",
       "      <td>-4764.041090</td>\n",
       "      <td>-4328.539734</td>\n",
       "      <td>-3949.643813</td>\n",
       "      <td>-3653.831266</td>\n",
       "      <td>-3439.275781</td>\n",
       "      <td>-3272.197182</td>\n",
       "      <td>-3106.030300</td>\n",
       "      <td>-2881.431954</td>\n",
       "      <td>-2542.708221</td>\n",
       "      <td>-2067.947699</td>\n",
       "      <td>-1450.758930</td>\n",
       "      <td>-722.183210</td>\n",
       "      <td>67.562203</td>\n",
       "      <td>850.005032</td>\n",
       "      <td>1561.232918</td>\n",
       "      <td>2152.858410</td>\n",
       "      <td>2601.141643</td>\n",
       "      <td>2912.474970</td>\n",
       "      <td>3123.378574</td>\n",
       "      <td>3286.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-910.262100</td>\n",
       "      <td>-312.245917</td>\n",
       "      <td>298.552078</td>\n",
       "      <td>896.568469</td>\n",
       "      <td>1462.629392</td>\n",
       "      <td>1978.474763</td>\n",
       "      <td>2439.540162</td>\n",
       "      <td>2847.652177</td>\n",
       "      <td>3212.852886</td>\n",
       "      <td>3547.924521</td>\n",
       "      <td>3868.387663</td>\n",
       "      <td>4181.547198</td>\n",
       "      <td>4492.881328</td>\n",
       "      <td>4794.170946</td>\n",
       "      <td>5070.810845</td>\n",
       "      <td>5302.712783</td>\n",
       "      <td>5471.618700</td>\n",
       "      <td>5560.180192</td>\n",
       "      <td>5560.179504</td>\n",
       "      <td>5470.705183</td>\n",
       "      <td>5300.886950</td>\n",
       "      <td>5067.159080</td>\n",
       "      <td>4790.519022</td>\n",
       "      <td>4490.142044</td>\n",
       "      <td>4180.634353</td>\n",
       "      <td>3865.648516</td>\n",
       "      <td>3545.184999</td>\n",
       "      <td>3210.114081</td>\n",
       "      <td>2844.912945</td>\n",
       "      <td>2436.801613</td>\n",
       "      <td>1975.735640</td>\n",
       "      <td>1458.977020</td>\n",
       "      <td>893.829119</td>\n",
       "      <td>295.812860</td>\n",
       "      <td>-314.984777</td>\n",
       "      <td>-913.001505</td>\n",
       "      <td>-1478.149395</td>\n",
       "      <td>-1994.907374</td>\n",
       "      <td>-2455.060500</td>\n",
       "      <td>-2863.172268</td>\n",
       "      <td>...</td>\n",
       "      <td>4179.721799</td>\n",
       "      <td>3864.736084</td>\n",
       "      <td>3544.272205</td>\n",
       "      <td>3209.200447</td>\n",
       "      <td>2844.000432</td>\n",
       "      <td>2435.888895</td>\n",
       "      <td>1974.823258</td>\n",
       "      <td>1458.063864</td>\n",
       "      <td>892.003398</td>\n",
       "      <td>293.074359</td>\n",
       "      <td>-317.724350</td>\n",
       "      <td>-915.740171</td>\n",
       "      <td>-1480.887539</td>\n",
       "      <td>-1995.820781</td>\n",
       "      <td>-2456.886440</td>\n",
       "      <td>-2864.085674</td>\n",
       "      <td>-3229.285738</td>\n",
       "      <td>-3564.357816</td>\n",
       "      <td>-3883.907629</td>\n",
       "      <td>-4197.980590</td>\n",
       "      <td>-4509.313669</td>\n",
       "      <td>-4810.604532</td>\n",
       "      <td>-5086.330695</td>\n",
       "      <td>-5318.233022</td>\n",
       "      <td>-5487.138172</td>\n",
       "      <td>-5575.699996</td>\n",
       "      <td>-5575.699390</td>\n",
       "      <td>-5485.312266</td>\n",
       "      <td>-5315.493812</td>\n",
       "      <td>-5082.678692</td>\n",
       "      <td>-4805.126485</td>\n",
       "      <td>-4506.574476</td>\n",
       "      <td>-4196.154858</td>\n",
       "      <td>-3881.168803</td>\n",
       "      <td>-3560.705563</td>\n",
       "      <td>-3225.633496</td>\n",
       "      <td>-2860.433401</td>\n",
       "      <td>-2452.321914</td>\n",
       "      <td>-1991.255895</td>\n",
       "      <td>-1474.497200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1            2    ...          125          126          127\n",
       "0  -797.962914 -1320.199586 -1828.741445  ...   790.659456   262.031836  -269.335205\n",
       "1  4387.885674  4567.747164  4693.741356  ...  3437.450839  3828.215741  4143.201102\n",
       "2 -4050.074299 -4340.408587 -4576.875995  ... -2861.346591 -3309.630078 -3706.785897\n",
       "3  3458.450134  3686.700705  4000.773209  ...  2912.474970  3123.378574  3286.805684\n",
       "4  -910.262100  -312.245917   298.552078  ... -2452.321914 -1991.255895 -1474.497200\n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(how='all', inplace = True)\n",
    "#df2.dropna(how='all', inplace = True)\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVLLv7qiVF5N"
   },
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(r'OutputFor_DataSet1.csv')\n",
    "t2 = pd.read_csv(r'OutputFor_DataSet2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GJDWRUVVF8D",
    "outputId": "672981d7-2e06-42fa-8797-620ac81e9ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5999, 1)\n",
      "(5999, 1)\n"
     ]
    }
   ],
   "source": [
    "t1.columns = ['target']\n",
    "t2.columns = ['target']\n",
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "df1['target'] = t1\n",
    "df2['target'] = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "AqMdSqd_VF_H",
    "outputId": "d889e86b-9d6f-4a7b-9722-e74a5bc40f85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "      <td>5999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-114.725650</td>\n",
       "      <td>-115.527708</td>\n",
       "      <td>-126.112360</td>\n",
       "      <td>-132.032136</td>\n",
       "      <td>-136.704447</td>\n",
       "      <td>-141.935573</td>\n",
       "      <td>-140.543493</td>\n",
       "      <td>-148.074137</td>\n",
       "      <td>-151.656233</td>\n",
       "      <td>-151.216996</td>\n",
       "      <td>-150.110683</td>\n",
       "      <td>-148.324022</td>\n",
       "      <td>-155.060516</td>\n",
       "      <td>-152.998291</td>\n",
       "      <td>-146.640704</td>\n",
       "      <td>-143.917558</td>\n",
       "      <td>-139.383508</td>\n",
       "      <td>-131.600967</td>\n",
       "      <td>-127.246435</td>\n",
       "      <td>-121.619322</td>\n",
       "      <td>-113.039008</td>\n",
       "      <td>-110.478671</td>\n",
       "      <td>-101.907954</td>\n",
       "      <td>-92.915332</td>\n",
       "      <td>-79.308630</td>\n",
       "      <td>-79.396437</td>\n",
       "      <td>-67.609323</td>\n",
       "      <td>-56.682444</td>\n",
       "      <td>-50.288095</td>\n",
       "      <td>-34.694330</td>\n",
       "      <td>-20.108317</td>\n",
       "      <td>-13.929643</td>\n",
       "      <td>-12.972290</td>\n",
       "      <td>-6.696286</td>\n",
       "      <td>-0.618427</td>\n",
       "      <td>10.899763</td>\n",
       "      <td>18.296962</td>\n",
       "      <td>23.424606</td>\n",
       "      <td>27.645966</td>\n",
       "      <td>28.355499</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.629376</td>\n",
       "      <td>-24.406372</td>\n",
       "      <td>-21.572649</td>\n",
       "      <td>-11.841742</td>\n",
       "      <td>-7.049046</td>\n",
       "      <td>-3.258422</td>\n",
       "      <td>1.151911</td>\n",
       "      <td>11.578695</td>\n",
       "      <td>18.961142</td>\n",
       "      <td>25.876065</td>\n",
       "      <td>33.238111</td>\n",
       "      <td>41.374223</td>\n",
       "      <td>49.421060</td>\n",
       "      <td>54.551175</td>\n",
       "      <td>56.392409</td>\n",
       "      <td>60.092876</td>\n",
       "      <td>75.126937</td>\n",
       "      <td>82.055212</td>\n",
       "      <td>86.668294</td>\n",
       "      <td>91.959960</td>\n",
       "      <td>98.077744</td>\n",
       "      <td>104.992452</td>\n",
       "      <td>111.051529</td>\n",
       "      <td>119.825115</td>\n",
       "      <td>126.854118</td>\n",
       "      <td>131.874435</td>\n",
       "      <td>132.129714</td>\n",
       "      <td>138.788062</td>\n",
       "      <td>145.936179</td>\n",
       "      <td>146.831518</td>\n",
       "      <td>152.991787</td>\n",
       "      <td>158.859205</td>\n",
       "      <td>162.352721</td>\n",
       "      <td>161.162793</td>\n",
       "      <td>163.662182</td>\n",
       "      <td>160.971389</td>\n",
       "      <td>156.814956</td>\n",
       "      <td>160.660116</td>\n",
       "      <td>149.550040</td>\n",
       "      <td>3.167028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4161.446816</td>\n",
       "      <td>4158.073346</td>\n",
       "      <td>4147.189662</td>\n",
       "      <td>4145.574877</td>\n",
       "      <td>4138.286796</td>\n",
       "      <td>4142.798449</td>\n",
       "      <td>4141.431760</td>\n",
       "      <td>4127.741826</td>\n",
       "      <td>4115.027973</td>\n",
       "      <td>4106.023447</td>\n",
       "      <td>4097.108911</td>\n",
       "      <td>4092.987618</td>\n",
       "      <td>4080.400646</td>\n",
       "      <td>4075.579711</td>\n",
       "      <td>4067.617308</td>\n",
       "      <td>4054.029633</td>\n",
       "      <td>4050.877334</td>\n",
       "      <td>4049.828071</td>\n",
       "      <td>4035.257338</td>\n",
       "      <td>4029.598680</td>\n",
       "      <td>4033.029087</td>\n",
       "      <td>4026.856665</td>\n",
       "      <td>4029.824397</td>\n",
       "      <td>4032.529267</td>\n",
       "      <td>4029.565201</td>\n",
       "      <td>4033.027680</td>\n",
       "      <td>4035.943930</td>\n",
       "      <td>4041.915977</td>\n",
       "      <td>4045.777910</td>\n",
       "      <td>4048.148249</td>\n",
       "      <td>4047.846148</td>\n",
       "      <td>4044.673887</td>\n",
       "      <td>4051.586594</td>\n",
       "      <td>4056.520051</td>\n",
       "      <td>4050.547657</td>\n",
       "      <td>4058.016866</td>\n",
       "      <td>4057.822252</td>\n",
       "      <td>4044.985899</td>\n",
       "      <td>4052.224383</td>\n",
       "      <td>4041.444446</td>\n",
       "      <td>...</td>\n",
       "      <td>4009.278098</td>\n",
       "      <td>4014.277079</td>\n",
       "      <td>4022.046258</td>\n",
       "      <td>4025.343377</td>\n",
       "      <td>4027.587735</td>\n",
       "      <td>4031.912007</td>\n",
       "      <td>4043.162924</td>\n",
       "      <td>4041.920091</td>\n",
       "      <td>4048.591813</td>\n",
       "      <td>4052.942752</td>\n",
       "      <td>4053.262909</td>\n",
       "      <td>4058.256221</td>\n",
       "      <td>4054.321852</td>\n",
       "      <td>4055.173782</td>\n",
       "      <td>4057.107309</td>\n",
       "      <td>4052.323972</td>\n",
       "      <td>4052.317167</td>\n",
       "      <td>4043.411406</td>\n",
       "      <td>4044.222471</td>\n",
       "      <td>4046.679083</td>\n",
       "      <td>4044.054613</td>\n",
       "      <td>4047.115512</td>\n",
       "      <td>4045.024272</td>\n",
       "      <td>4046.507354</td>\n",
       "      <td>4050.384826</td>\n",
       "      <td>4047.751336</td>\n",
       "      <td>4047.469645</td>\n",
       "      <td>4052.089380</td>\n",
       "      <td>4055.809144</td>\n",
       "      <td>4063.864101</td>\n",
       "      <td>4072.775492</td>\n",
       "      <td>4083.708212</td>\n",
       "      <td>4092.957306</td>\n",
       "      <td>4102.078879</td>\n",
       "      <td>4110.569834</td>\n",
       "      <td>4114.955656</td>\n",
       "      <td>4126.345999</td>\n",
       "      <td>4130.068579</td>\n",
       "      <td>4136.623246</td>\n",
       "      <td>1.404314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7141.830542</td>\n",
       "      <td>-7045.699667</td>\n",
       "      <td>-7073.957462</td>\n",
       "      <td>-7132.801634</td>\n",
       "      <td>-7108.402036</td>\n",
       "      <td>-7126.645918</td>\n",
       "      <td>-7001.727133</td>\n",
       "      <td>-7090.700202</td>\n",
       "      <td>-7112.356784</td>\n",
       "      <td>-7072.899446</td>\n",
       "      <td>-7128.268195</td>\n",
       "      <td>-6998.465183</td>\n",
       "      <td>-7035.872427</td>\n",
       "      <td>-7125.278595</td>\n",
       "      <td>-7184.126245</td>\n",
       "      <td>-7071.719736</td>\n",
       "      <td>-7161.582101</td>\n",
       "      <td>-7031.171860</td>\n",
       "      <td>-7042.861531</td>\n",
       "      <td>-7132.357863</td>\n",
       "      <td>-7002.480030</td>\n",
       "      <td>-7067.784583</td>\n",
       "      <td>-7116.963289</td>\n",
       "      <td>-6987.365883</td>\n",
       "      <td>-7024.374970</td>\n",
       "      <td>-7114.738185</td>\n",
       "      <td>-7070.833136</td>\n",
       "      <td>-7161.793897</td>\n",
       "      <td>-7031.379542</td>\n",
       "      <td>-6948.831863</td>\n",
       "      <td>-7084.546755</td>\n",
       "      <td>-7175.684320</td>\n",
       "      <td>-7045.017440</td>\n",
       "      <td>-7085.637268</td>\n",
       "      <td>-7175.675988</td>\n",
       "      <td>-7045.009328</td>\n",
       "      <td>-7099.842027</td>\n",
       "      <td>-7061.962522</td>\n",
       "      <td>-7152.809002</td>\n",
       "      <td>-7101.292081</td>\n",
       "      <td>...</td>\n",
       "      <td>-7114.738466</td>\n",
       "      <td>-7071.928458</td>\n",
       "      <td>-7161.794070</td>\n",
       "      <td>-7030.284436</td>\n",
       "      <td>-6948.832156</td>\n",
       "      <td>-7085.644495</td>\n",
       "      <td>-7175.683857</td>\n",
       "      <td>-7043.919000</td>\n",
       "      <td>-7084.539054</td>\n",
       "      <td>-7175.675810</td>\n",
       "      <td>-7045.010017</td>\n",
       "      <td>-7099.841926</td>\n",
       "      <td>-7063.056170</td>\n",
       "      <td>-7152.808720</td>\n",
       "      <td>-7101.292398</td>\n",
       "      <td>-7048.325565</td>\n",
       "      <td>-7061.059757</td>\n",
       "      <td>-7117.889307</td>\n",
       "      <td>-7179.089133</td>\n",
       "      <td>-7048.361074</td>\n",
       "      <td>-7124.885331</td>\n",
       "      <td>-6994.053168</td>\n",
       "      <td>-7094.305654</td>\n",
       "      <td>-7185.568806</td>\n",
       "      <td>-7175.660203</td>\n",
       "      <td>-7043.895540</td>\n",
       "      <td>-7125.971639</td>\n",
       "      <td>-7178.973510</td>\n",
       "      <td>-7067.268198</td>\n",
       "      <td>-7091.174661</td>\n",
       "      <td>-7132.989578</td>\n",
       "      <td>-7156.597198</td>\n",
       "      <td>-7026.277853</td>\n",
       "      <td>-7009.518740</td>\n",
       "      <td>-7099.691389</td>\n",
       "      <td>-7111.826303</td>\n",
       "      <td>-7150.132885</td>\n",
       "      <td>-7081.591335</td>\n",
       "      <td>-7052.215609</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4160.971201</td>\n",
       "      <td>-4120.892883</td>\n",
       "      <td>-4125.239779</td>\n",
       "      <td>-4119.606384</td>\n",
       "      <td>-4133.306556</td>\n",
       "      <td>-4181.006164</td>\n",
       "      <td>-4191.995756</td>\n",
       "      <td>-4207.688652</td>\n",
       "      <td>-4207.246651</td>\n",
       "      <td>-4166.475247</td>\n",
       "      <td>-4107.537205</td>\n",
       "      <td>-4132.118199</td>\n",
       "      <td>-4095.826008</td>\n",
       "      <td>-4065.274250</td>\n",
       "      <td>-4005.427578</td>\n",
       "      <td>-4004.909897</td>\n",
       "      <td>-4006.373730</td>\n",
       "      <td>-4011.626377</td>\n",
       "      <td>-4032.907248</td>\n",
       "      <td>-4020.170564</td>\n",
       "      <td>-3924.365627</td>\n",
       "      <td>-3906.624172</td>\n",
       "      <td>-3900.809279</td>\n",
       "      <td>-3892.815003</td>\n",
       "      <td>-3903.940399</td>\n",
       "      <td>-3968.160585</td>\n",
       "      <td>-3946.011621</td>\n",
       "      <td>-3900.883722</td>\n",
       "      <td>-3925.676707</td>\n",
       "      <td>-3890.655688</td>\n",
       "      <td>-3912.243137</td>\n",
       "      <td>-3922.814750</td>\n",
       "      <td>-3974.595476</td>\n",
       "      <td>-3954.148085</td>\n",
       "      <td>-3900.067352</td>\n",
       "      <td>-3869.874169</td>\n",
       "      <td>-3863.378852</td>\n",
       "      <td>-3832.064062</td>\n",
       "      <td>-3873.744391</td>\n",
       "      <td>-3865.822350</td>\n",
       "      <td>...</td>\n",
       "      <td>-3884.537227</td>\n",
       "      <td>-3902.777198</td>\n",
       "      <td>-3860.441439</td>\n",
       "      <td>-3869.539119</td>\n",
       "      <td>-3859.728759</td>\n",
       "      <td>-3913.292046</td>\n",
       "      <td>-3956.113024</td>\n",
       "      <td>-3933.425230</td>\n",
       "      <td>-3915.929220</td>\n",
       "      <td>-3886.722516</td>\n",
       "      <td>-3885.021687</td>\n",
       "      <td>-3865.100142</td>\n",
       "      <td>-3876.614969</td>\n",
       "      <td>-3880.774381</td>\n",
       "      <td>-3874.383253</td>\n",
       "      <td>-3860.394207</td>\n",
       "      <td>-3808.913162</td>\n",
       "      <td>-3794.681318</td>\n",
       "      <td>-3800.172652</td>\n",
       "      <td>-3843.518924</td>\n",
       "      <td>-3815.688332</td>\n",
       "      <td>-3823.284882</td>\n",
       "      <td>-3787.028081</td>\n",
       "      <td>-3759.321447</td>\n",
       "      <td>-3744.537284</td>\n",
       "      <td>-3761.973628</td>\n",
       "      <td>-3795.776658</td>\n",
       "      <td>-3797.981098</td>\n",
       "      <td>-3769.985899</td>\n",
       "      <td>-3802.507174</td>\n",
       "      <td>-3783.789669</td>\n",
       "      <td>-3813.809418</td>\n",
       "      <td>-3810.812432</td>\n",
       "      <td>-3823.675412</td>\n",
       "      <td>-3808.576083</td>\n",
       "      <td>-3840.850780</td>\n",
       "      <td>-3870.966424</td>\n",
       "      <td>-3880.440523</td>\n",
       "      <td>-3946.438423</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-53.971220</td>\n",
       "      <td>-16.851957</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>-17.450357</td>\n",
       "      <td>-33.230153</td>\n",
       "      <td>-45.507217</td>\n",
       "      <td>-49.491354</td>\n",
       "      <td>-56.113130</td>\n",
       "      <td>-49.545925</td>\n",
       "      <td>-16.029965</td>\n",
       "      <td>-47.023873</td>\n",
       "      <td>-45.759849</td>\n",
       "      <td>-31.937613</td>\n",
       "      <td>-32.096770</td>\n",
       "      <td>-48.105056</td>\n",
       "      <td>-57.963254</td>\n",
       "      <td>-63.675309</td>\n",
       "      <td>-77.517922</td>\n",
       "      <td>-69.131244</td>\n",
       "      <td>-50.567020</td>\n",
       "      <td>-49.276679</td>\n",
       "      <td>-37.068232</td>\n",
       "      <td>-46.656751</td>\n",
       "      <td>-47.214141</td>\n",
       "      <td>-54.643305</td>\n",
       "      <td>-60.832364</td>\n",
       "      <td>-53.419163</td>\n",
       "      <td>-49.842920</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>1.081870</td>\n",
       "      <td>33.115272</td>\n",
       "      <td>35.253083</td>\n",
       "      <td>17.999379</td>\n",
       "      <td>0.927458</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>1.083172</td>\n",
       "      <td>1.037311</td>\n",
       "      <td>17.791296</td>\n",
       "      <td>35.255221</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.346330</td>\n",
       "      <td>-47.756817</td>\n",
       "      <td>-35.885764</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>19.310754</td>\n",
       "      <td>34.022191</td>\n",
       "      <td>31.179814</td>\n",
       "      <td>32.423947</td>\n",
       "      <td>0.976886</td>\n",
       "      <td>-2.117513</td>\n",
       "      <td>1.083620</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.989805</td>\n",
       "      <td>19.310668</td>\n",
       "      <td>19.485070</td>\n",
       "      <td>18.380627</td>\n",
       "      <td>0.910059</td>\n",
       "      <td>19.630333</td>\n",
       "      <td>16.391669</td>\n",
       "      <td>0.987582</td>\n",
       "      <td>0.937244</td>\n",
       "      <td>32.751809</td>\n",
       "      <td>49.210932</td>\n",
       "      <td>39.824034</td>\n",
       "      <td>57.495764</td>\n",
       "      <td>52.336229</td>\n",
       "      <td>33.141414</td>\n",
       "      <td>30.079875</td>\n",
       "      <td>16.800867</td>\n",
       "      <td>0.980716</td>\n",
       "      <td>31.213399</td>\n",
       "      <td>37.370717</td>\n",
       "      <td>37.790866</td>\n",
       "      <td>38.546879</td>\n",
       "      <td>38.530495</td>\n",
       "      <td>-2.132272</td>\n",
       "      <td>-16.327000</td>\n",
       "      <td>-33.220181</td>\n",
       "      <td>-36.290691</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3993.059373</td>\n",
       "      <td>3975.606918</td>\n",
       "      <td>3941.862785</td>\n",
       "      <td>3934.786941</td>\n",
       "      <td>3895.807969</td>\n",
       "      <td>3883.944640</td>\n",
       "      <td>3900.523695</td>\n",
       "      <td>3867.409249</td>\n",
       "      <td>3873.427547</td>\n",
       "      <td>3852.206124</td>\n",
       "      <td>3823.065720</td>\n",
       "      <td>3800.822265</td>\n",
       "      <td>3790.377104</td>\n",
       "      <td>3765.375978</td>\n",
       "      <td>3760.195919</td>\n",
       "      <td>3726.641171</td>\n",
       "      <td>3734.576567</td>\n",
       "      <td>3717.806545</td>\n",
       "      <td>3746.376796</td>\n",
       "      <td>3778.326921</td>\n",
       "      <td>3752.028224</td>\n",
       "      <td>3753.510861</td>\n",
       "      <td>3784.006873</td>\n",
       "      <td>3759.712357</td>\n",
       "      <td>3761.990859</td>\n",
       "      <td>3779.598765</td>\n",
       "      <td>3796.178696</td>\n",
       "      <td>3788.719699</td>\n",
       "      <td>3821.189344</td>\n",
       "      <td>3847.115099</td>\n",
       "      <td>3900.191313</td>\n",
       "      <td>3927.343133</td>\n",
       "      <td>3894.599316</td>\n",
       "      <td>3888.575621</td>\n",
       "      <td>3888.211868</td>\n",
       "      <td>3910.219912</td>\n",
       "      <td>3922.083558</td>\n",
       "      <td>3927.681255</td>\n",
       "      <td>3949.254227</td>\n",
       "      <td>3946.822868</td>\n",
       "      <td>...</td>\n",
       "      <td>3831.571642</td>\n",
       "      <td>3813.802370</td>\n",
       "      <td>3790.510884</td>\n",
       "      <td>3832.634975</td>\n",
       "      <td>3852.022363</td>\n",
       "      <td>3877.791676</td>\n",
       "      <td>3951.185742</td>\n",
       "      <td>3911.824907</td>\n",
       "      <td>3941.147741</td>\n",
       "      <td>3938.511635</td>\n",
       "      <td>3929.810629</td>\n",
       "      <td>3967.672131</td>\n",
       "      <td>3991.996516</td>\n",
       "      <td>4017.857686</td>\n",
       "      <td>4012.285316</td>\n",
       "      <td>4020.467303</td>\n",
       "      <td>4017.950127</td>\n",
       "      <td>3999.106005</td>\n",
       "      <td>4029.518670</td>\n",
       "      <td>3992.015901</td>\n",
       "      <td>3957.037078</td>\n",
       "      <td>3980.083665</td>\n",
       "      <td>3967.098379</td>\n",
       "      <td>3976.901248</td>\n",
       "      <td>4027.926882</td>\n",
       "      <td>4069.373407</td>\n",
       "      <td>4072.690418</td>\n",
       "      <td>4007.319653</td>\n",
       "      <td>4016.729365</td>\n",
       "      <td>4027.278084</td>\n",
       "      <td>4092.631326</td>\n",
       "      <td>4095.965436</td>\n",
       "      <td>4214.789824</td>\n",
       "      <td>4168.641604</td>\n",
       "      <td>4187.898994</td>\n",
       "      <td>4181.453477</td>\n",
       "      <td>4171.886726</td>\n",
       "      <td>4238.594092</td>\n",
       "      <td>4265.958464</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10114.640580</td>\n",
       "      <td>10159.376130</td>\n",
       "      <td>10089.248290</td>\n",
       "      <td>10127.495060</td>\n",
       "      <td>9534.475944</td>\n",
       "      <td>10025.702560</td>\n",
       "      <td>10163.965400</td>\n",
       "      <td>10247.909840</td>\n",
       "      <td>9894.417610</td>\n",
       "      <td>10215.751070</td>\n",
       "      <td>9708.120072</td>\n",
       "      <td>9889.823554</td>\n",
       "      <td>9140.324838</td>\n",
       "      <td>9812.629679</td>\n",
       "      <td>9980.642300</td>\n",
       "      <td>10152.104430</td>\n",
       "      <td>9792.720520</td>\n",
       "      <td>9927.862870</td>\n",
       "      <td>10013.463520</td>\n",
       "      <td>9898.141367</td>\n",
       "      <td>9534.667108</td>\n",
       "      <td>10147.426330</td>\n",
       "      <td>9909.611663</td>\n",
       "      <td>9943.007450</td>\n",
       "      <td>10100.724540</td>\n",
       "      <td>9875.957475</td>\n",
       "      <td>10042.237040</td>\n",
       "      <td>10235.855300</td>\n",
       "      <td>9995.968646</td>\n",
       "      <td>10065.707100</td>\n",
       "      <td>10152.252600</td>\n",
       "      <td>9962.020713</td>\n",
       "      <td>10129.749220</td>\n",
       "      <td>10054.193580</td>\n",
       "      <td>10072.359210</td>\n",
       "      <td>10161.416390</td>\n",
       "      <td>10240.724010</td>\n",
       "      <td>9371.647704</td>\n",
       "      <td>10087.425510</td>\n",
       "      <td>9066.803633</td>\n",
       "      <td>...</td>\n",
       "      <td>7007.662469</td>\n",
       "      <td>6992.137234</td>\n",
       "      <td>7081.223423</td>\n",
       "      <td>7093.327236</td>\n",
       "      <td>7131.533662</td>\n",
       "      <td>7063.170483</td>\n",
       "      <td>7033.637957</td>\n",
       "      <td>7123.252305</td>\n",
       "      <td>7027.372196</td>\n",
       "      <td>7055.556381</td>\n",
       "      <td>7114.247305</td>\n",
       "      <td>7089.911545</td>\n",
       "      <td>7108.107216</td>\n",
       "      <td>6983.282775</td>\n",
       "      <td>7072.255180</td>\n",
       "      <td>7093.855433</td>\n",
       "      <td>7054.500960</td>\n",
       "      <td>7109.726461</td>\n",
       "      <td>6979.922803</td>\n",
       "      <td>7017.337235</td>\n",
       "      <td>7106.744649</td>\n",
       "      <td>7165.439135</td>\n",
       "      <td>7053.090719</td>\n",
       "      <td>7142.952944</td>\n",
       "      <td>7011.446927</td>\n",
       "      <td>7024.308836</td>\n",
       "      <td>7113.804901</td>\n",
       "      <td>6983.927072</td>\n",
       "      <td>7049.400160</td>\n",
       "      <td>7098.451122</td>\n",
       "      <td>6967.764591</td>\n",
       "      <td>7006.956608</td>\n",
       "      <td>7096.231519</td>\n",
       "      <td>7053.299319</td>\n",
       "      <td>7143.164258</td>\n",
       "      <td>7010.558409</td>\n",
       "      <td>6930.756469</td>\n",
       "      <td>7066.979036</td>\n",
       "      <td>7157.018214</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1  ...          127       target\n",
       "count   5999.000000   5999.000000  ...  5999.000000  5999.000000\n",
       "mean    -114.725650   -115.527708  ...   149.550040     3.167028\n",
       "std     4161.446816   4158.073346  ...  4136.623246     1.404314\n",
       "min    -7141.830542  -7045.699667  ... -7052.215609     1.000000\n",
       "25%    -4160.971201  -4120.892883  ... -3946.438423     2.000000\n",
       "50%      -53.971220    -16.851957  ...   -36.290691     3.000000\n",
       "75%     3993.059373   3975.606918  ...  4265.958464     4.500000\n",
       "max    10114.640580  10159.376130  ...  7157.018214     5.000000\n",
       "\n",
       "[8 rows x 129 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "l2w2p2e_VGB9",
    "outputId": "a4cf9568-277f-4f18-d1c1-c9197208c4a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11998, 129)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-797.962914</td>\n",
       "      <td>-1320.199586</td>\n",
       "      <td>-1828.741445</td>\n",
       "      <td>-2319.935857</td>\n",
       "      <td>-2789.218649</td>\n",
       "      <td>-3231.111864</td>\n",
       "      <td>-3641.962908</td>\n",
       "      <td>-4018.119193</td>\n",
       "      <td>-4355.929647</td>\n",
       "      <td>-4650.829055</td>\n",
       "      <td>-4904.643864</td>\n",
       "      <td>-5107.330184</td>\n",
       "      <td>-5261.626825</td>\n",
       "      <td>-5366.622879</td>\n",
       "      <td>-5418.663525</td>\n",
       "      <td>-5419.576973</td>\n",
       "      <td>-5367.535249</td>\n",
       "      <td>-5264.365732</td>\n",
       "      <td>-5110.069166</td>\n",
       "      <td>-4906.470001</td>\n",
       "      <td>-4656.307539</td>\n",
       "      <td>-4364.146538</td>\n",
       "      <td>-4024.510575</td>\n",
       "      <td>-3650.179436</td>\n",
       "      <td>-3239.328934</td>\n",
       "      <td>-2797.436518</td>\n",
       "      <td>-2329.066729</td>\n",
       "      <td>-1837.871278</td>\n",
       "      <td>-1329.329968</td>\n",
       "      <td>-808.005760</td>\n",
       "      <td>-278.465093</td>\n",
       "      <td>252.902023</td>\n",
       "      <td>782.442935</td>\n",
       "      <td>1303.766529</td>\n",
       "      <td>1812.308746</td>\n",
       "      <td>2303.502822</td>\n",
       "      <td>2772.785644</td>\n",
       "      <td>3215.592255</td>\n",
       "      <td>3626.442570</td>\n",
       "      <td>4002.599102</td>\n",
       "      <td>...</td>\n",
       "      <td>-2797.435948</td>\n",
       "      <td>-2329.066521</td>\n",
       "      <td>-1837.871910</td>\n",
       "      <td>-1329.329479</td>\n",
       "      <td>-808.005477</td>\n",
       "      <td>-279.377475</td>\n",
       "      <td>252.901869</td>\n",
       "      <td>781.530215</td>\n",
       "      <td>1303.767033</td>\n",
       "      <td>1812.308177</td>\n",
       "      <td>2304.416161</td>\n",
       "      <td>2773.699506</td>\n",
       "      <td>3215.591849</td>\n",
       "      <td>3627.355635</td>\n",
       "      <td>4002.598697</td>\n",
       "      <td>4340.409797</td>\n",
       "      <td>4635.308762</td>\n",
       "      <td>4889.123899</td>\n",
       "      <td>5091.809794</td>\n",
       "      <td>5246.107486</td>\n",
       "      <td>5351.102295</td>\n",
       "      <td>5403.143675</td>\n",
       "      <td>5403.143732</td>\n",
       "      <td>5351.102775</td>\n",
       "      <td>5247.932927</td>\n",
       "      <td>5093.636278</td>\n",
       "      <td>4889.123913</td>\n",
       "      <td>4639.874673</td>\n",
       "      <td>4346.800923</td>\n",
       "      <td>4008.077109</td>\n",
       "      <td>3632.834002</td>\n",
       "      <td>3221.982426</td>\n",
       "      <td>2780.090228</td>\n",
       "      <td>2311.720161</td>\n",
       "      <td>1821.438861</td>\n",
       "      <td>1311.983509</td>\n",
       "      <td>790.659456</td>\n",
       "      <td>262.031836</td>\n",
       "      <td>-269.335205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4387.885674</td>\n",
       "      <td>4567.747164</td>\n",
       "      <td>4693.741356</td>\n",
       "      <td>4776.824895</td>\n",
       "      <td>4824.300958</td>\n",
       "      <td>4850.777519</td>\n",
       "      <td>4862.646175</td>\n",
       "      <td>4867.211521</td>\n",
       "      <td>4866.298624</td>\n",
       "      <td>4858.081691</td>\n",
       "      <td>4839.821272</td>\n",
       "      <td>4801.475225</td>\n",
       "      <td>4735.739730</td>\n",
       "      <td>4633.482680</td>\n",
       "      <td>4480.098867</td>\n",
       "      <td>4263.717062</td>\n",
       "      <td>3982.513234</td>\n",
       "      <td>3625.529989</td>\n",
       "      <td>3194.592586</td>\n",
       "      <td>2690.615580</td>\n",
       "      <td>2121.815686</td>\n",
       "      <td>1499.149171</td>\n",
       "      <td>836.309474</td>\n",
       "      <td>150.645858</td>\n",
       "      <td>-539.583464</td>\n",
       "      <td>-1214.291896</td>\n",
       "      <td>-1857.957949</td>\n",
       "      <td>-2453.234297</td>\n",
       "      <td>-2987.340713</td>\n",
       "      <td>-3452.058138</td>\n",
       "      <td>-3842.822995</td>\n",
       "      <td>-4158.721282</td>\n",
       "      <td>-4403.405653</td>\n",
       "      <td>-4583.267220</td>\n",
       "      <td>-4709.261054</td>\n",
       "      <td>-4793.257930</td>\n",
       "      <td>-4839.820962</td>\n",
       "      <td>-4866.297128</td>\n",
       "      <td>-4879.079514</td>\n",
       "      <td>-4882.731612</td>\n",
       "      <td>...</td>\n",
       "      <td>-1217.030331</td>\n",
       "      <td>-1860.696745</td>\n",
       "      <td>-2455.060932</td>\n",
       "      <td>-2989.166228</td>\n",
       "      <td>-3453.883859</td>\n",
       "      <td>-3844.648379</td>\n",
       "      <td>-4159.634438</td>\n",
       "      <td>-4404.318373</td>\n",
       "      <td>-4583.266716</td>\n",
       "      <td>-4709.261622</td>\n",
       "      <td>-4793.257592</td>\n",
       "      <td>-4839.820102</td>\n",
       "      <td>-4866.297534</td>\n",
       "      <td>-4879.079451</td>\n",
       "      <td>-4882.732017</td>\n",
       "      <td>-4881.818474</td>\n",
       "      <td>-4873.601984</td>\n",
       "      <td>-4855.341237</td>\n",
       "      <td>-4817.908616</td>\n",
       "      <td>-4751.259069</td>\n",
       "      <td>-4649.003265</td>\n",
       "      <td>-4496.531718</td>\n",
       "      <td>-4279.237302</td>\n",
       "      <td>-3998.032706</td>\n",
       "      <td>-3641.049793</td>\n",
       "      <td>-3210.112473</td>\n",
       "      <td>-2706.135664</td>\n",
       "      <td>-2137.335549</td>\n",
       "      <td>-1514.668783</td>\n",
       "      <td>-850.916937</td>\n",
       "      <td>-165.252287</td>\n",
       "      <td>524.062959</td>\n",
       "      <td>1199.684611</td>\n",
       "      <td>1842.437384</td>\n",
       "      <td>2437.714882</td>\n",
       "      <td>2972.733259</td>\n",
       "      <td>3437.450839</td>\n",
       "      <td>3828.215741</td>\n",
       "      <td>4143.201102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4050.074299</td>\n",
       "      <td>-4340.408587</td>\n",
       "      <td>-4576.875995</td>\n",
       "      <td>-4769.518913</td>\n",
       "      <td>-4918.338175</td>\n",
       "      <td>-5025.159834</td>\n",
       "      <td>-5100.026323</td>\n",
       "      <td>-5141.111052</td>\n",
       "      <td>-5153.892968</td>\n",
       "      <td>-5137.458861</td>\n",
       "      <td>-5091.809174</td>\n",
       "      <td>-5014.204029</td>\n",
       "      <td>-4900.078226</td>\n",
       "      <td>-4746.694853</td>\n",
       "      <td>-4552.225090</td>\n",
       "      <td>-4306.628130</td>\n",
       "      <td>-4008.988999</td>\n",
       "      <td>-3659.309075</td>\n",
       "      <td>-3255.763095</td>\n",
       "      <td>-2801.088514</td>\n",
       "      <td>-2298.024633</td>\n",
       "      <td>-1753.875216</td>\n",
       "      <td>-1176.858860</td>\n",
       "      <td>-577.929348</td>\n",
       "      <td>31.955483</td>\n",
       "      <td>640.927176</td>\n",
       "      <td>1237.117177</td>\n",
       "      <td>1809.569762</td>\n",
       "      <td>2349.153124</td>\n",
       "      <td>2845.826291</td>\n",
       "      <td>3295.022824</td>\n",
       "      <td>3691.265717</td>\n",
       "      <td>4034.554320</td>\n",
       "      <td>4323.975530</td>\n",
       "      <td>4561.356298</td>\n",
       "      <td>4753.998880</td>\n",
       "      <td>4902.818171</td>\n",
       "      <td>5009.640226</td>\n",
       "      <td>5084.505985</td>\n",
       "      <td>5125.590961</td>\n",
       "      <td>...</td>\n",
       "      <td>640.014744</td>\n",
       "      <td>1236.204383</td>\n",
       "      <td>1808.656128</td>\n",
       "      <td>2348.240611</td>\n",
       "      <td>2844.913572</td>\n",
       "      <td>3294.110443</td>\n",
       "      <td>3691.265562</td>\n",
       "      <td>4033.641600</td>\n",
       "      <td>4323.976034</td>\n",
       "      <td>4561.355729</td>\n",
       "      <td>4753.999218</td>\n",
       "      <td>4902.819032</td>\n",
       "      <td>5009.639820</td>\n",
       "      <td>5083.593047</td>\n",
       "      <td>5125.590557</td>\n",
       "      <td>5138.373119</td>\n",
       "      <td>5121.938568</td>\n",
       "      <td>5076.289209</td>\n",
       "      <td>4998.683639</td>\n",
       "      <td>4884.558887</td>\n",
       "      <td>4730.261267</td>\n",
       "      <td>4536.705240</td>\n",
       "      <td>4291.107890</td>\n",
       "      <td>3993.469527</td>\n",
       "      <td>3643.789270</td>\n",
       "      <td>3240.243209</td>\n",
       "      <td>2784.655428</td>\n",
       "      <td>2281.591768</td>\n",
       "      <td>1738.355604</td>\n",
       "      <td>1161.338395</td>\n",
       "      <td>563.322919</td>\n",
       "      <td>-47.475988</td>\n",
       "      <td>-656.447463</td>\n",
       "      <td>-1252.637741</td>\n",
       "      <td>-1825.089177</td>\n",
       "      <td>-2364.673580</td>\n",
       "      <td>-2861.346591</td>\n",
       "      <td>-3309.630078</td>\n",
       "      <td>-3706.785897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3458.450134</td>\n",
       "      <td>3686.700705</td>\n",
       "      <td>4000.773209</td>\n",
       "      <td>4392.451258</td>\n",
       "      <td>4834.343975</td>\n",
       "      <td>5269.845213</td>\n",
       "      <td>5636.871457</td>\n",
       "      <td>5876.078192</td>\n",
       "      <td>5950.944421</td>\n",
       "      <td>5841.384319</td>\n",
       "      <td>5574.787489</td>\n",
       "      <td>5187.674864</td>\n",
       "      <td>4745.782747</td>\n",
       "      <td>4310.280145</td>\n",
       "      <td>3932.297960</td>\n",
       "      <td>3637.398025</td>\n",
       "      <td>3422.843307</td>\n",
       "      <td>3256.677378</td>\n",
       "      <td>3089.597412</td>\n",
       "      <td>2864.998869</td>\n",
       "      <td>2526.275355</td>\n",
       "      <td>2051.515086</td>\n",
       "      <td>1433.412463</td>\n",
       "      <td>704.837776</td>\n",
       "      <td>-84.908711</td>\n",
       "      <td>-866.438320</td>\n",
       "      <td>-1578.579486</td>\n",
       "      <td>-2169.290827</td>\n",
       "      <td>-2616.662099</td>\n",
       "      <td>-2928.908272</td>\n",
       "      <td>-3138.898830</td>\n",
       "      <td>-3303.238866</td>\n",
       "      <td>-3473.970114</td>\n",
       "      <td>-3702.220761</td>\n",
       "      <td>-4015.379905</td>\n",
       "      <td>-4406.145289</td>\n",
       "      <td>-4848.037975</td>\n",
       "      <td>-5283.538819</td>\n",
       "      <td>-5651.478793</td>\n",
       "      <td>-5891.598282</td>\n",
       "      <td>...</td>\n",
       "      <td>-865.524749</td>\n",
       "      <td>-1577.666277</td>\n",
       "      <td>-2169.291459</td>\n",
       "      <td>-2617.574612</td>\n",
       "      <td>-2928.907989</td>\n",
       "      <td>-3138.898210</td>\n",
       "      <td>-3303.239020</td>\n",
       "      <td>-3473.969832</td>\n",
       "      <td>-3702.220257</td>\n",
       "      <td>-4015.380473</td>\n",
       "      <td>-4407.057953</td>\n",
       "      <td>-4848.037115</td>\n",
       "      <td>-5283.539225</td>\n",
       "      <td>-5650.565728</td>\n",
       "      <td>-5890.685686</td>\n",
       "      <td>-5966.464270</td>\n",
       "      <td>-5857.817614</td>\n",
       "      <td>-5592.133458</td>\n",
       "      <td>-5205.021257</td>\n",
       "      <td>-4764.041090</td>\n",
       "      <td>-4328.539734</td>\n",
       "      <td>-3949.643813</td>\n",
       "      <td>-3653.831266</td>\n",
       "      <td>-3439.275781</td>\n",
       "      <td>-3272.197182</td>\n",
       "      <td>-3106.030300</td>\n",
       "      <td>-2881.431954</td>\n",
       "      <td>-2542.708221</td>\n",
       "      <td>-2067.947699</td>\n",
       "      <td>-1450.758930</td>\n",
       "      <td>-722.183210</td>\n",
       "      <td>67.562203</td>\n",
       "      <td>850.005032</td>\n",
       "      <td>1561.232918</td>\n",
       "      <td>2152.858410</td>\n",
       "      <td>2601.141643</td>\n",
       "      <td>2912.474970</td>\n",
       "      <td>3123.378574</td>\n",
       "      <td>3286.805684</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-910.262100</td>\n",
       "      <td>-312.245917</td>\n",
       "      <td>298.552078</td>\n",
       "      <td>896.568469</td>\n",
       "      <td>1462.629392</td>\n",
       "      <td>1978.474763</td>\n",
       "      <td>2439.540162</td>\n",
       "      <td>2847.652177</td>\n",
       "      <td>3212.852886</td>\n",
       "      <td>3547.924521</td>\n",
       "      <td>3868.387663</td>\n",
       "      <td>4181.547198</td>\n",
       "      <td>4492.881328</td>\n",
       "      <td>4794.170946</td>\n",
       "      <td>5070.810845</td>\n",
       "      <td>5302.712783</td>\n",
       "      <td>5471.618700</td>\n",
       "      <td>5560.180192</td>\n",
       "      <td>5560.179504</td>\n",
       "      <td>5470.705183</td>\n",
       "      <td>5300.886950</td>\n",
       "      <td>5067.159080</td>\n",
       "      <td>4790.519022</td>\n",
       "      <td>4490.142044</td>\n",
       "      <td>4180.634353</td>\n",
       "      <td>3865.648516</td>\n",
       "      <td>3545.184999</td>\n",
       "      <td>3210.114081</td>\n",
       "      <td>2844.912945</td>\n",
       "      <td>2436.801613</td>\n",
       "      <td>1975.735640</td>\n",
       "      <td>1458.977020</td>\n",
       "      <td>893.829119</td>\n",
       "      <td>295.812860</td>\n",
       "      <td>-314.984777</td>\n",
       "      <td>-913.001505</td>\n",
       "      <td>-1478.149395</td>\n",
       "      <td>-1994.907374</td>\n",
       "      <td>-2455.060500</td>\n",
       "      <td>-2863.172268</td>\n",
       "      <td>...</td>\n",
       "      <td>3864.736084</td>\n",
       "      <td>3544.272205</td>\n",
       "      <td>3209.200447</td>\n",
       "      <td>2844.000432</td>\n",
       "      <td>2435.888895</td>\n",
       "      <td>1974.823258</td>\n",
       "      <td>1458.063864</td>\n",
       "      <td>892.003398</td>\n",
       "      <td>293.074359</td>\n",
       "      <td>-317.724350</td>\n",
       "      <td>-915.740171</td>\n",
       "      <td>-1480.887539</td>\n",
       "      <td>-1995.820781</td>\n",
       "      <td>-2456.886440</td>\n",
       "      <td>-2864.085674</td>\n",
       "      <td>-3229.285738</td>\n",
       "      <td>-3564.357816</td>\n",
       "      <td>-3883.907629</td>\n",
       "      <td>-4197.980590</td>\n",
       "      <td>-4509.313669</td>\n",
       "      <td>-4810.604532</td>\n",
       "      <td>-5086.330695</td>\n",
       "      <td>-5318.233022</td>\n",
       "      <td>-5487.138172</td>\n",
       "      <td>-5575.699996</td>\n",
       "      <td>-5575.699390</td>\n",
       "      <td>-5485.312266</td>\n",
       "      <td>-5315.493812</td>\n",
       "      <td>-5082.678692</td>\n",
       "      <td>-4805.126485</td>\n",
       "      <td>-4506.574476</td>\n",
       "      <td>-4196.154858</td>\n",
       "      <td>-3881.168803</td>\n",
       "      <td>-3560.705563</td>\n",
       "      <td>-3225.633496</td>\n",
       "      <td>-2860.433401</td>\n",
       "      <td>-2452.321914</td>\n",
       "      <td>-1991.255895</td>\n",
       "      <td>-1474.497200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2  ...          126          127  target\n",
       "0  -797.962914 -1320.199586 -1828.741445  ...   262.031836  -269.335205       1\n",
       "1  4387.885674  4567.747164  4693.741356  ...  3828.215741  4143.201102       2\n",
       "2 -4050.074299 -4340.408587 -4576.875995  ... -3309.630078 -3706.785897       2\n",
       "3  3458.450134  3686.700705  4000.773209  ...  3123.378574  3286.805684       3\n",
       "4  -910.262100  -312.245917   298.552078  ... -1991.255895 -1474.497200       3\n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df1.append(df2, ignore_index=True)\n",
    "class1 = df3[df3['target']==1]\n",
    "class2 = df3[df3['target']==2]\n",
    "class3 = df3[df3['target']==3]\n",
    "class4 = df3[df3['target']==4]\n",
    "class5 = df3[df3['target']==5]\n",
    "print(df3.shape)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NDzgaiZVGEz"
   },
   "outputs": [],
   "source": [
    "X = df3.iloc[:,0:128]\n",
    "y = df3.iloc[:,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "D5AlfE0cVOFd",
    "outputId": "87d4650e-cde3-46cf-8814-95a31ed303e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11998 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3  4  5\n",
       "0      1  0  0  0  0\n",
       "1      0  1  0  0  0\n",
       "2      0  1  0  0  0\n",
       "3      0  0  1  0  0\n",
       "4      0  0  1  0  0\n",
       "...   .. .. .. .. ..\n",
       "11993  0  0  0  1  0\n",
       "11994  0  0  0  1  0\n",
       "11995  0  0  0  0  1\n",
       "11996  0  0  0  0  1\n",
       "11997  0  0  0  0  1\n",
       "\n",
       "[11998 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.get_dummies(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7_Z7E1NVOIi",
    "outputId": "e2c5a085-c762-4a9a-9647-a0896f9166aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "X_tr, X_t, y_tr, y_t = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "num_classes = len(np.unique(y_t))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dLniYekVOLV",
    "outputId": "c0f77b48-95de-471f-e554-8b94a9a67da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 16,805\n",
      "Trainable params: 16,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(32,input_dim = X.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(64,activation='relu'))\n",
    "NN_model.add(Dense(64,activation='relu'))\n",
    "NN_model.add(Dense(64 ,activation='relu'))\n",
    "NN_model.add(Dense(32,kernel_regularizer=keras.regularizers.l2() ,activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# Compile the network :\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "NN_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zw4dXU0X29b"
   },
   "outputs": [],
   "source": [
    "ACCURACY_THRESHOLD = 0.99\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "      if(logs.get('accuracy') > ACCURACY_THRESHOLD):     \n",
    "        print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
    "        self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjumkDC5VOOU",
    "outputId": "c114d503-a1c4-470d-e3f6-d1c0b4d592ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "141/141 [==============================] - 3s 5ms/step - loss: 1.7911 - accuracy: 0.3119 - val_loss: 1.2720 - val_accuracy: 0.4167\n",
      "Epoch 2/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.4379 - val_loss: 1.1940 - val_accuracy: 0.4317\n",
      "Epoch 3/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.2023 - accuracy: 0.4226 - val_loss: 1.2776 - val_accuracy: 0.3980\n",
      "Epoch 4/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1779 - accuracy: 0.4226 - val_loss: 1.1702 - val_accuracy: 0.4137\n",
      "Epoch 5/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1640 - accuracy: 0.4195 - val_loss: 1.1633 - val_accuracy: 0.4290\n",
      "Epoch 6/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1526 - accuracy: 0.4324 - val_loss: 1.1585 - val_accuracy: 0.4273\n",
      "Epoch 7/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1502 - accuracy: 0.4308 - val_loss: 1.3404 - val_accuracy: 0.3643\n",
      "Epoch 8/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1502 - accuracy: 0.4296 - val_loss: 1.1468 - val_accuracy: 0.4317\n",
      "Epoch 9/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1598 - accuracy: 0.4304 - val_loss: 1.1588 - val_accuracy: 0.4143\n",
      "Epoch 10/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1462 - accuracy: 0.4334 - val_loss: 1.1416 - val_accuracy: 0.4333\n",
      "Epoch 11/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1399 - accuracy: 0.4359 - val_loss: 1.1409 - val_accuracy: 0.4450\n",
      "Epoch 12/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1364 - accuracy: 0.4355 - val_loss: 1.1427 - val_accuracy: 0.4380\n",
      "Epoch 13/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1427 - accuracy: 0.4333 - val_loss: 1.1402 - val_accuracy: 0.4530\n",
      "Epoch 14/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1430 - accuracy: 0.4371 - val_loss: 1.1408 - val_accuracy: 0.4440\n",
      "Epoch 15/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1442 - accuracy: 0.4360 - val_loss: 1.1372 - val_accuracy: 0.4433\n",
      "Epoch 16/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1451 - accuracy: 0.4326 - val_loss: 1.1398 - val_accuracy: 0.4310\n",
      "Epoch 17/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1358 - accuracy: 0.4524 - val_loss: 1.1591 - val_accuracy: 0.4213\n",
      "Epoch 18/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1437 - accuracy: 0.4429 - val_loss: 1.1428 - val_accuracy: 0.4283\n",
      "Epoch 19/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1402 - accuracy: 0.4455 - val_loss: 1.1400 - val_accuracy: 0.4567\n",
      "Epoch 20/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1294 - accuracy: 0.4593 - val_loss: 1.1363 - val_accuracy: 0.4363\n",
      "Epoch 21/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1173 - accuracy: 0.4670 - val_loss: 1.1269 - val_accuracy: 0.4547\n",
      "Epoch 22/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1342 - accuracy: 0.4551 - val_loss: 1.1349 - val_accuracy: 0.4440\n",
      "Epoch 23/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1150 - accuracy: 0.4682 - val_loss: 1.1266 - val_accuracy: 0.4360\n",
      "Epoch 24/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.1080 - accuracy: 0.4755 - val_loss: 1.1401 - val_accuracy: 0.4587\n",
      "Epoch 25/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.0845 - accuracy: 0.4849 - val_loss: 1.0923 - val_accuracy: 0.4690\n",
      "Epoch 26/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 1.0354 - accuracy: 0.5313 - val_loss: 1.0232 - val_accuracy: 0.5183\n",
      "Epoch 27/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.5560 - val_loss: 1.1012 - val_accuracy: 0.4730\n",
      "Epoch 28/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.9663 - accuracy: 0.5687 - val_loss: 0.8719 - val_accuracy: 0.6350\n",
      "Epoch 29/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.9381 - accuracy: 0.5901 - val_loss: 0.9312 - val_accuracy: 0.5890\n",
      "Epoch 30/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.9067 - accuracy: 0.5994 - val_loss: 0.8723 - val_accuracy: 0.6043\n",
      "Epoch 31/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9108 - accuracy: 0.5900 - val_loss: 1.0334 - val_accuracy: 0.5330\n",
      "Epoch 32/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.9082 - accuracy: 0.5801 - val_loss: 0.9007 - val_accuracy: 0.5987\n",
      "Epoch 33/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.8605 - accuracy: 0.6193 - val_loss: 0.7234 - val_accuracy: 0.6857\n",
      "Epoch 34/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.8356 - accuracy: 0.6290 - val_loss: 0.9784 - val_accuracy: 0.5607\n",
      "Epoch 35/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.8284 - accuracy: 0.6299 - val_loss: 0.9282 - val_accuracy: 0.5730\n",
      "Epoch 36/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.6325 - val_loss: 1.2288 - val_accuracy: 0.5223\n",
      "Epoch 37/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.6458 - val_loss: 0.8056 - val_accuracy: 0.6190\n",
      "Epoch 38/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7736 - accuracy: 0.6619 - val_loss: 0.9619 - val_accuracy: 0.5807\n",
      "Epoch 39/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7866 - accuracy: 0.6500 - val_loss: 0.7595 - val_accuracy: 0.6623\n",
      "Epoch 40/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6745 - val_loss: 0.9705 - val_accuracy: 0.5933\n",
      "Epoch 41/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.6799 - val_loss: 1.0826 - val_accuracy: 0.5583\n",
      "Epoch 42/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.6834 - val_loss: 0.7414 - val_accuracy: 0.6673\n",
      "Epoch 43/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.6997 - val_loss: 0.9382 - val_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7162 - val_loss: 0.5613 - val_accuracy: 0.7653\n",
      "Epoch 45/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7189 - val_loss: 0.8858 - val_accuracy: 0.6500\n",
      "Epoch 46/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7161 - val_loss: 0.8531 - val_accuracy: 0.6407\n",
      "Epoch 47/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.7298 - val_loss: 0.5658 - val_accuracy: 0.7290\n",
      "Epoch 48/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7378 - val_loss: 0.7331 - val_accuracy: 0.7467\n",
      "Epoch 49/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7569 - val_loss: 0.8739 - val_accuracy: 0.6650\n",
      "Epoch 50/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.7494 - val_loss: 0.6730 - val_accuracy: 0.6990\n",
      "Epoch 51/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7687 - val_loss: 0.7052 - val_accuracy: 0.7100\n",
      "Epoch 52/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7576 - val_loss: 0.6798 - val_accuracy: 0.6793\n",
      "Epoch 53/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7868 - val_loss: 0.6130 - val_accuracy: 0.7640\n",
      "Epoch 54/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7803 - val_loss: 0.4701 - val_accuracy: 0.7997\n",
      "Epoch 55/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7896 - val_loss: 0.4247 - val_accuracy: 0.8243\n",
      "Epoch 56/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7982 - val_loss: 0.4307 - val_accuracy: 0.8280\n",
      "Epoch 57/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7939 - val_loss: 0.5336 - val_accuracy: 0.7583\n",
      "Epoch 58/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8001 - val_loss: 0.6075 - val_accuracy: 0.7297\n",
      "Epoch 59/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8040 - val_loss: 0.6690 - val_accuracy: 0.7113\n",
      "Epoch 60/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8106 - val_loss: 0.6048 - val_accuracy: 0.7337\n",
      "Epoch 61/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8119 - val_loss: 0.6377 - val_accuracy: 0.7347\n",
      "Epoch 62/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8023 - val_loss: 0.4422 - val_accuracy: 0.7913\n",
      "Epoch 63/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.8159 - val_loss: 0.4069 - val_accuracy: 0.8240\n",
      "Epoch 64/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8251 - val_loss: 0.6244 - val_accuracy: 0.7323\n",
      "Epoch 65/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8276 - val_loss: 0.3558 - val_accuracy: 0.8357\n",
      "Epoch 66/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4256 - accuracy: 0.8272 - val_loss: 0.3792 - val_accuracy: 0.8477\n",
      "Epoch 67/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8425 - val_loss: 0.2939 - val_accuracy: 0.8900\n",
      "Epoch 68/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8349 - val_loss: 0.5615 - val_accuracy: 0.7580\n",
      "Epoch 69/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8428 - val_loss: 0.3174 - val_accuracy: 0.8807\n",
      "Epoch 70/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8558 - val_loss: 0.3044 - val_accuracy: 0.8843\n",
      "Epoch 71/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8568 - val_loss: 0.4396 - val_accuracy: 0.8137\n",
      "Epoch 72/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3477 - accuracy: 0.8632 - val_loss: 0.3538 - val_accuracy: 0.8647\n",
      "Epoch 73/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8571 - val_loss: 0.8901 - val_accuracy: 0.7097\n",
      "Epoch 74/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8395 - val_loss: 0.3527 - val_accuracy: 0.8547\n",
      "Epoch 75/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8771 - val_loss: 0.2549 - val_accuracy: 0.8930\n",
      "Epoch 76/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8725 - val_loss: 0.2664 - val_accuracy: 0.8880\n",
      "Epoch 77/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8784 - val_loss: 0.2685 - val_accuracy: 0.8887\n",
      "Epoch 78/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8684 - val_loss: 0.5361 - val_accuracy: 0.7933\n",
      "Epoch 79/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8538 - val_loss: 0.2964 - val_accuracy: 0.8687\n",
      "Epoch 80/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8842 - val_loss: 0.2833 - val_accuracy: 0.8753\n",
      "Epoch 81/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8685 - val_loss: 0.3421 - val_accuracy: 0.8570\n",
      "Epoch 82/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8740 - val_loss: 0.3591 - val_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.8879 - val_loss: 0.3058 - val_accuracy: 0.8643\n",
      "Epoch 84/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8786 - val_loss: 0.1966 - val_accuracy: 0.9293\n",
      "Epoch 85/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8957 - val_loss: 0.1988 - val_accuracy: 0.9140\n",
      "Epoch 86/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.8914 - val_loss: 0.2130 - val_accuracy: 0.9193\n",
      "Epoch 87/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.8860 - val_loss: 0.2577 - val_accuracy: 0.8893\n",
      "Epoch 88/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.8954 - val_loss: 0.5821 - val_accuracy: 0.7740\n",
      "Epoch 89/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8953 - val_loss: 0.1441 - val_accuracy: 0.9467\n",
      "Epoch 90/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8915 - val_loss: 0.3744 - val_accuracy: 0.8410\n",
      "Epoch 91/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8965 - val_loss: 0.3516 - val_accuracy: 0.8550\n",
      "Epoch 92/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9054 - val_loss: 0.2534 - val_accuracy: 0.8817\n",
      "Epoch 93/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.8952 - val_loss: 0.2234 - val_accuracy: 0.9120\n",
      "Epoch 94/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8976 - val_loss: 0.1700 - val_accuracy: 0.9450\n",
      "Epoch 95/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.8906 - val_loss: 0.1398 - val_accuracy: 0.9523\n",
      "Epoch 96/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8906 - val_loss: 0.1961 - val_accuracy: 0.9253\n",
      "Epoch 97/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8962 - val_loss: 0.2031 - val_accuracy: 0.9123\n",
      "Epoch 98/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9136 - val_loss: 0.2800 - val_accuracy: 0.8783\n",
      "Epoch 99/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8973 - val_loss: 0.5851 - val_accuracy: 0.7727\n",
      "Epoch 100/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.9027 - val_loss: 0.2265 - val_accuracy: 0.9050\n",
      "Epoch 101/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9075 - val_loss: 0.2785 - val_accuracy: 0.8793\n",
      "Epoch 102/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9111 - val_loss: 0.1143 - val_accuracy: 0.9627\n",
      "Epoch 103/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9089 - val_loss: 0.1915 - val_accuracy: 0.9157\n",
      "Epoch 104/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9141 - val_loss: 0.1451 - val_accuracy: 0.9450\n",
      "Epoch 105/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9171 - val_loss: 0.3434 - val_accuracy: 0.8583\n",
      "Epoch 106/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9173 - val_loss: 1.8289 - val_accuracy: 0.6673\n",
      "Epoch 107/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.9103 - val_loss: 0.1553 - val_accuracy: 0.9390\n",
      "Epoch 108/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9216 - val_loss: 0.2041 - val_accuracy: 0.9213\n",
      "Epoch 109/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9157 - val_loss: 0.1007 - val_accuracy: 0.9710\n",
      "Epoch 110/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9341 - val_loss: 0.3399 - val_accuracy: 0.8880\n",
      "Epoch 111/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9253 - val_loss: 0.5519 - val_accuracy: 0.7897\n",
      "Epoch 112/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9228 - val_loss: 0.1390 - val_accuracy: 0.9460\n",
      "Epoch 113/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9000 - val_loss: 0.1721 - val_accuracy: 0.9397\n",
      "Epoch 114/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9206 - val_loss: 0.1073 - val_accuracy: 0.9627\n",
      "Epoch 115/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1934 - accuracy: 0.9293 - val_loss: 0.1167 - val_accuracy: 0.9620\n",
      "Epoch 116/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9340 - val_loss: 0.2364 - val_accuracy: 0.8997\n",
      "Epoch 117/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9282 - val_loss: 0.1323 - val_accuracy: 0.9557\n",
      "Epoch 118/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9272 - val_loss: 0.0973 - val_accuracy: 0.9657\n",
      "Epoch 119/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.9235 - val_loss: 0.1116 - val_accuracy: 0.9590\n",
      "Epoch 120/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9128 - val_loss: 0.2796 - val_accuracy: 0.8997\n",
      "Epoch 121/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9282 - val_loss: 0.0675 - val_accuracy: 0.9797\n",
      "Epoch 122/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9365 - val_loss: 0.3320 - val_accuracy: 0.8650\n",
      "Epoch 123/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2353 - accuracy: 0.9111 - val_loss: 0.2771 - val_accuracy: 0.8840\n",
      "Epoch 124/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9210 - val_loss: 0.1768 - val_accuracy: 0.9367\n",
      "Epoch 125/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9349 - val_loss: 0.0831 - val_accuracy: 0.9747\n",
      "Epoch 126/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9370 - val_loss: 0.5579 - val_accuracy: 0.7840\n",
      "Epoch 127/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9210 - val_loss: 0.0965 - val_accuracy: 0.9673\n",
      "Epoch 128/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9319 - val_loss: 0.3385 - val_accuracy: 0.8647\n",
      "Epoch 129/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9171 - val_loss: 0.2296 - val_accuracy: 0.9220\n",
      "Epoch 130/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9380 - val_loss: 0.3190 - val_accuracy: 0.8787\n",
      "Epoch 131/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9366 - val_loss: 0.0759 - val_accuracy: 0.9760\n",
      "Epoch 132/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9403 - val_loss: 0.0803 - val_accuracy: 0.9740\n",
      "Epoch 133/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9277 - val_loss: 0.0715 - val_accuracy: 0.9750\n",
      "Epoch 134/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9422 - val_loss: 0.3350 - val_accuracy: 0.8620\n",
      "Epoch 135/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 0.0781 - val_accuracy: 0.9783\n",
      "Epoch 136/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9371 - val_loss: 0.1167 - val_accuracy: 0.9643\n",
      "Epoch 137/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9267 - val_loss: 0.2192 - val_accuracy: 0.9207\n",
      "Epoch 138/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9227 - val_loss: 0.2685 - val_accuracy: 0.8877\n",
      "Epoch 139/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9263 - val_loss: 0.0609 - val_accuracy: 0.9863\n",
      "Epoch 140/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9429 - val_loss: 0.0717 - val_accuracy: 0.9857\n",
      "Epoch 141/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1560 - accuracy: 0.9433 - val_loss: 0.0438 - val_accuracy: 0.9953\n",
      "Epoch 142/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9479 - val_loss: 0.0564 - val_accuracy: 0.9847\n",
      "Epoch 143/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1815 - accuracy: 0.9360 - val_loss: 0.0372 - val_accuracy: 0.9960\n",
      "Epoch 144/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9369 - val_loss: 0.0840 - val_accuracy: 0.9673\n",
      "Epoch 145/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9478 - val_loss: 0.5006 - val_accuracy: 0.8087\n",
      "Epoch 146/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9357 - val_loss: 0.0652 - val_accuracy: 0.9823\n",
      "Epoch 147/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1569 - accuracy: 0.9476 - val_loss: 0.0915 - val_accuracy: 0.9657\n",
      "Epoch 148/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9514 - val_loss: 0.0429 - val_accuracy: 0.9893\n",
      "Epoch 149/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9402 - val_loss: 0.3071 - val_accuracy: 0.8623\n",
      "Epoch 150/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9421 - val_loss: 0.0527 - val_accuracy: 0.9873\n",
      "Epoch 151/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9419 - val_loss: 0.2367 - val_accuracy: 0.9100\n",
      "Epoch 152/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9464 - val_loss: 0.0634 - val_accuracy: 0.9787\n",
      "Epoch 153/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9364 - val_loss: 0.2012 - val_accuracy: 0.9180\n",
      "Epoch 154/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9526 - val_loss: 0.2421 - val_accuracy: 0.8940\n",
      "Epoch 155/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9446 - val_loss: 0.0296 - val_accuracy: 0.9977\n",
      "Epoch 156/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9503 - val_loss: 0.0371 - val_accuracy: 0.9893\n",
      "Epoch 157/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1706 - accuracy: 0.9465 - val_loss: 0.3369 - val_accuracy: 0.8707\n",
      "Epoch 158/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9416 - val_loss: 0.2601 - val_accuracy: 0.9097\n",
      "Epoch 159/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9333 - val_loss: 0.0456 - val_accuracy: 0.9923\n",
      "Epoch 160/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1366 - accuracy: 0.9560 - val_loss: 1.3337 - val_accuracy: 0.7267\n",
      "Epoch 161/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2171 - accuracy: 0.9306 - val_loss: 0.1274 - val_accuracy: 0.9473\n",
      "Epoch 162/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9495 - val_loss: 0.0392 - val_accuracy: 0.9947\n",
      "Epoch 163/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.9588 - val_loss: 0.2392 - val_accuracy: 0.9073\n",
      "Epoch 164/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9515 - val_loss: 0.3088 - val_accuracy: 0.8817\n",
      "Epoch 165/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9356 - val_loss: 0.1697 - val_accuracy: 0.9163\n",
      "Epoch 166/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1503 - accuracy: 0.9470 - val_loss: 0.0299 - val_accuracy: 0.9943\n",
      "Epoch 167/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9591 - val_loss: 0.0600 - val_accuracy: 0.9810\n",
      "Epoch 168/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9498 - val_loss: 0.3265 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1367 - accuracy: 0.9576 - val_loss: 0.0247 - val_accuracy: 0.9993\n",
      "Epoch 170/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9427 - val_loss: 0.1494 - val_accuracy: 0.9440\n",
      "Epoch 171/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1359 - accuracy: 0.9524 - val_loss: 0.4092 - val_accuracy: 0.8373\n",
      "Epoch 172/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9460 - val_loss: 0.3202 - val_accuracy: 0.8877\n",
      "Epoch 173/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9485 - val_loss: 0.0624 - val_accuracy: 0.9853\n",
      "Epoch 174/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9475 - val_loss: 0.0228 - val_accuracy: 0.9963\n",
      "Epoch 175/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9639 - val_loss: 0.0473 - val_accuracy: 0.9870\n",
      "Epoch 176/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9548 - val_loss: 0.0377 - val_accuracy: 0.9957\n",
      "Epoch 177/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9632 - val_loss: 1.1689 - val_accuracy: 0.6990\n",
      "Epoch 178/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9507 - val_loss: 0.5482 - val_accuracy: 0.7867\n",
      "Epoch 179/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1834 - accuracy: 0.9469 - val_loss: 0.0336 - val_accuracy: 0.9953\n",
      "Epoch 180/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9527 - val_loss: 0.0170 - val_accuracy: 0.9980\n",
      "Epoch 181/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.9345 - val_loss: 0.0631 - val_accuracy: 0.9880\n",
      "Epoch 182/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9402 - val_loss: 0.0108 - val_accuracy: 0.9980\n",
      "Epoch 183/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9418 - val_loss: 0.0211 - val_accuracy: 0.9973\n",
      "Epoch 184/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9576 - val_loss: 0.0409 - val_accuracy: 0.9923\n",
      "Epoch 185/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9633 - val_loss: 0.0311 - val_accuracy: 0.9953\n",
      "Epoch 186/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1159 - accuracy: 0.9664 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
      "Epoch 187/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9603 - val_loss: 0.1057 - val_accuracy: 0.9680\n",
      "Epoch 188/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9565 - val_loss: 0.1542 - val_accuracy: 0.9437\n",
      "Epoch 189/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9581 - val_loss: 0.0242 - val_accuracy: 0.9967\n",
      "Epoch 190/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9563 - val_loss: 0.0317 - val_accuracy: 0.9920\n",
      "Epoch 191/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9604 - val_loss: 0.0172 - val_accuracy: 0.9990\n",
      "Epoch 192/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9656 - val_loss: 0.1525 - val_accuracy: 0.9313\n",
      "Epoch 193/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9753 - val_loss: 0.3460 - val_accuracy: 0.8717\n",
      "Epoch 194/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9510 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9704 - val_loss: 0.0347 - val_accuracy: 0.9927\n",
      "Epoch 196/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1297 - accuracy: 0.9627 - val_loss: 0.0611 - val_accuracy: 0.9810\n",
      "Epoch 197/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9690 - val_loss: 0.1711 - val_accuracy: 0.9363\n",
      "Epoch 198/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9681 - val_loss: 0.0193 - val_accuracy: 0.9950\n",
      "Epoch 199/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9590 - val_loss: 0.1570 - val_accuracy: 0.9470\n",
      "Epoch 200/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1232 - accuracy: 0.9598 - val_loss: 0.1210 - val_accuracy: 0.9487\n",
      "Epoch 201/1000\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9565 - val_loss: 0.0111 - val_accuracy: 0.9990\n",
      "Epoch 202/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9696 - val_loss: 0.1273 - val_accuracy: 0.9507\n",
      "Epoch 203/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9615 - val_loss: 0.5002 - val_accuracy: 0.7983\n",
      "Epoch 204/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9494 - val_loss: 0.0113 - val_accuracy: 0.9993\n",
      "Epoch 205/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9666 - val_loss: 0.5080 - val_accuracy: 0.8233\n",
      "Epoch 206/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9584 - val_loss: 0.0767 - val_accuracy: 0.9713\n",
      "Epoch 207/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1815 - accuracy: 0.9484 - val_loss: 0.4018 - val_accuracy: 0.8563\n",
      "Epoch 208/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9636 - val_loss: 0.0986 - val_accuracy: 0.9547\n",
      "Epoch 209/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9597 - val_loss: 0.5317 - val_accuracy: 0.8423\n",
      "Epoch 210/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9547 - val_loss: 0.1357 - val_accuracy: 0.9553\n",
      "Epoch 211/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9599 - val_loss: 0.0441 - val_accuracy: 0.9913\n",
      "Epoch 212/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9583 - val_loss: 0.0115 - val_accuracy: 0.9993\n",
      "Epoch 213/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1381 - accuracy: 0.9614 - val_loss: 0.0327 - val_accuracy: 0.9917\n",
      "Epoch 214/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 215/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9515 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1202 - accuracy: 0.9633 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9693 - val_loss: 0.2233 - val_accuracy: 0.9273\n",
      "Epoch 218/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9676 - val_loss: 0.0870 - val_accuracy: 0.9760\n",
      "Epoch 219/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9704 - val_loss: 0.0654 - val_accuracy: 0.9867\n",
      "Epoch 220/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9760 - val_loss: 0.0163 - val_accuracy: 0.9973\n",
      "Epoch 221/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9679 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 222/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9643 - val_loss: 0.0512 - val_accuracy: 0.9857\n",
      "Epoch 223/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9689 - val_loss: 0.0150 - val_accuracy: 0.9997\n",
      "Epoch 224/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.9557 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
      "Epoch 225/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9535 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
      "Epoch 226/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9717 - val_loss: 0.1062 - val_accuracy: 0.9653\n",
      "Epoch 227/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9654 - val_loss: 0.1441 - val_accuracy: 0.9507\n",
      "Epoch 228/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9781 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
      "Epoch 229/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9845 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9803 - val_loss: 0.0323 - val_accuracy: 0.9957\n",
      "Epoch 231/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9741 - val_loss: 0.0089 - val_accuracy: 0.9997\n",
      "Epoch 232/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9712 - val_loss: 0.0840 - val_accuracy: 0.9790\n",
      "Epoch 233/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9749 - val_loss: 0.0078 - val_accuracy: 0.9997\n",
      "Epoch 234/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9768 - val_loss: 0.0185 - val_accuracy: 0.9967\n",
      "Epoch 235/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9629 - val_loss: 0.0660 - val_accuracy: 0.9840\n",
      "Epoch 236/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9664 - val_loss: 0.5671 - val_accuracy: 0.7953\n",
      "Epoch 237/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9431 - val_loss: 0.0936 - val_accuracy: 0.9710\n",
      "Epoch 238/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.1735 - val_accuracy: 0.9237\n",
      "Epoch 239/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9580 - val_loss: 0.0109 - val_accuracy: 0.9983\n",
      "Epoch 240/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9622 - val_loss: 0.2124 - val_accuracy: 0.9083\n",
      "Epoch 241/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9671 - val_loss: 0.0228 - val_accuracy: 0.9953\n",
      "Epoch 242/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9517 - val_loss: 0.0337 - val_accuracy: 0.9927\n",
      "Epoch 243/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9712 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9701 - val_loss: 0.0260 - val_accuracy: 0.9960\n",
      "Epoch 245/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9773 - val_loss: 0.0125 - val_accuracy: 0.9983\n",
      "Epoch 246/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9726 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9656 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9575 - val_loss: 0.0281 - val_accuracy: 0.9933\n",
      "Epoch 249/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9741 - val_loss: 0.0148 - val_accuracy: 0.9983\n",
      "Epoch 250/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9748 - val_loss: 0.0158 - val_accuracy: 0.9967\n",
      "Epoch 251/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9702 - val_loss: 0.2167 - val_accuracy: 0.9250\n",
      "Epoch 252/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9753 - val_loss: 0.0111 - val_accuracy: 0.9983\n",
      "Epoch 253/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9620 - val_loss: 0.0559 - val_accuracy: 0.9863\n",
      "Epoch 254/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9773 - val_loss: 0.0137 - val_accuracy: 0.9977\n",
      "Epoch 255/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9757 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9777 - val_loss: 0.1479 - val_accuracy: 0.9473\n",
      "Epoch 257/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9641 - val_loss: 0.2067 - val_accuracy: 0.9100\n",
      "Epoch 258/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1572 - accuracy: 0.9502 - val_loss: 0.2970 - val_accuracy: 0.8793\n",
      "Epoch 259/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9710 - val_loss: 0.1947 - val_accuracy: 0.9280\n",
      "Epoch 260/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9729 - val_loss: 0.0767 - val_accuracy: 0.9833\n",
      "Epoch 261/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9668 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1685 - accuracy: 0.9574 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9596 - val_loss: 0.3717 - val_accuracy: 0.8507\n",
      "Epoch 264/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9715 - val_loss: 0.0676 - val_accuracy: 0.9777\n",
      "Epoch 265/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9662 - val_loss: 0.0131 - val_accuracy: 0.9977\n",
      "Epoch 266/1000\n",
      "141/141 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9657 - val_loss: 2.3625 - val_accuracy: 0.6367\n",
      "Epoch 267/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9536 - val_loss: 0.0271 - val_accuracy: 0.9957\n",
      "Epoch 268/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9850 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9798 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1176 - accuracy: 0.9713 - val_loss: 0.2480 - val_accuracy: 0.9003\n",
      "Epoch 271/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9747 - val_loss: 0.0241 - val_accuracy: 0.9950\n",
      "Epoch 272/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.3944 - val_accuracy: 0.8483\n",
      "Epoch 273/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9696 - val_loss: 0.0816 - val_accuracy: 0.9730\n",
      "Epoch 274/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9788 - val_loss: 0.0194 - val_accuracy: 0.9967\n",
      "Epoch 275/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9817 - val_loss: 0.0184 - val_accuracy: 0.9980\n",
      "Epoch 276/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9804 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9649 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9849 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1317 - accuracy: 0.9706 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9593 - val_loss: 0.0077 - val_accuracy: 0.9987\n",
      "Epoch 281/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.9504 - val_loss: 0.0048 - val_accuracy: 0.9997\n",
      "Epoch 282/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1247 - accuracy: 0.9764 - val_loss: 0.0887 - val_accuracy: 0.9740\n",
      "Epoch 283/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1155 - accuracy: 0.9724 - val_loss: 0.0509 - val_accuracy: 0.9853\n",
      "Epoch 284/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9748 - val_loss: 0.1055 - val_accuracy: 0.9797\n",
      "Epoch 285/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1684 - accuracy: 0.9841 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.9592 - val_loss: 0.3926 - val_accuracy: 0.8723\n",
      "Epoch 287/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9636 - val_loss: 0.0117 - val_accuracy: 0.9983\n",
      "Epoch 288/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9675 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9667 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.0091 - val_accuracy: 0.9990\n",
      "Epoch 291/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0865 - accuracy: 0.9786 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1684 - accuracy: 0.9519 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9582 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9544 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.9841 - val_loss: 0.0104 - val_accuracy: 0.9990\n",
      "Epoch 296/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9688 - val_loss: 0.0084 - val_accuracy: 0.9997\n",
      "Epoch 297/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2131 - accuracy: 0.9829 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9751 - val_loss: 0.0232 - val_accuracy: 0.9970\n",
      "Epoch 299/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9853 - val_loss: 0.4337 - val_accuracy: 0.8460\n",
      "Epoch 300/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1045 - accuracy: 0.9740 - val_loss: 0.0769 - val_accuracy: 0.9873\n",
      "Epoch 301/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1163 - accuracy: 0.9658 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
      "Epoch 302/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9774 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9732 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9806 - val_loss: 0.0343 - val_accuracy: 0.9953\n",
      "Epoch 305/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.1556 - val_accuracy: 0.9487\n",
      "Epoch 306/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9601 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5117 - accuracy: 0.9646 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9682 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9719 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9856 - val_loss: 0.7545 - val_accuracy: 0.7190\n",
      "Epoch 311/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1254 - accuracy: 0.9576 - val_loss: 0.1905 - val_accuracy: 0.9233\n",
      "Epoch 312/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9674 - val_loss: 0.1542 - val_accuracy: 0.9383\n",
      "Epoch 313/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9691 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.9369 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
      "Epoch 315/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9858 - val_loss: 0.0682 - val_accuracy: 0.9717\n",
      "Epoch 316/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9586 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9764 - val_loss: 0.3791 - val_accuracy: 0.8720\n",
      "Epoch 318/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9627 - val_loss: 0.1399 - val_accuracy: 0.9473\n",
      "Epoch 319/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9848 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1791 - accuracy: 0.9768 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.9528 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9609 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 323/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9789 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0972 - accuracy: 0.9855 - val_loss: 0.0268 - val_accuracy: 0.9950\n",
      "Epoch 325/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9742 - val_loss: 0.0175 - val_accuracy: 0.9973\n",
      "Epoch 326/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9841 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1241 - accuracy: 0.9756 - val_loss: 0.0231 - val_accuracy: 0.9920\n",
      "Epoch 328/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9773 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1209 - accuracy: 0.9753 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9636 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9807 - val_loss: 0.0345 - val_accuracy: 0.9953\n",
      "Epoch 332/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0598 - accuracy: 0.9845 - val_loss: 0.0171 - val_accuracy: 0.9967\n",
      "Epoch 333/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9601 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1495 - accuracy: 0.9730 - val_loss: 0.0737 - val_accuracy: 0.9877\n",
      "Epoch 335/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9835 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9680 - val_loss: 0.6992 - val_accuracy: 0.7720\n",
      "Epoch 337/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9580 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9744 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9669 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
      "Epoch 340/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9856 - val_loss: 0.0810 - val_accuracy: 0.9760\n",
      "Epoch 341/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9784 - val_loss: 0.0413 - val_accuracy: 0.9910\n",
      "Epoch 342/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9747 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9891 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Reached 99.00% accuracy, so stopping training!!\n"
     ]
    }
   ],
   "source": [
    "history = NN_model.fit(X, Y, epochs=1000, batch_size=64, validation_split = 0.25, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydkXA8X8ZJq8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er8sUUUQVOQ8",
    "outputId": "b80febc5-4848-4ded-bf38-06e15baa9118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_12.h/assets\n",
      "INFO:tensorflow:Assets written to: model_13.tflite/assets\n"
     ]
    }
   ],
   "source": [
    "NN_model.save(\"model_11.h5\")\n",
    "NN_model.save(\"model_12.h\")\n",
    "NN_model.save(\"model_13.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "2WFbN4o9VdEU",
    "outputId": "05ec01bb-f200-45f8-998e-863498e8d369"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_acc(history):\n",
    "    plt.plot(history.history['loss'][1:])\n",
    "    plt.plot(history.history['val_loss'][1:])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'][1:])\n",
    "    plt.plot(history.history['val_accuracy'][1:])\n",
    "    plt.title('model Accuracy')\n",
    "    plt.ylabel('val_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tXfULPvb-Ia",
    "outputId": "7752d823-71f6-408b-86f7-7b17322a1ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(X[:])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, Y, test_size = 0.25,random_state = 120)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)\n",
    "\n",
    "input_shape=(x_train.shape[1], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBBv6vxbVdHN",
    "outputId": "c4abe60e-2704-4ad8-a29c-20f44cf8e190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 24s 116ms/step - loss: 1.5862 - accuracy: 0.2628 - val_loss: 1.3396 - val_accuracy: 0.3477\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 16s 111ms/step - loss: 1.3841 - accuracy: 0.3914 - val_loss: 1.2739 - val_accuracy: 0.4113\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 1.2404 - accuracy: 0.4762 - val_loss: 1.1865 - val_accuracy: 0.4430\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.9922 - accuracy: 0.5575 - val_loss: 2.9170 - val_accuracy: 0.3823\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.9981 - accuracy: 0.5902 - val_loss: 0.7002 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.8037 - accuracy: 0.6324 - val_loss: 1.1634 - val_accuracy: 0.5020\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.7761 - accuracy: 0.6334 - val_loss: 2.1292 - val_accuracy: 0.3420\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 16s 112ms/step - loss: 0.7882 - accuracy: 0.6300 - val_loss: 0.6980 - val_accuracy: 0.6430\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.7275 - accuracy: 0.6553 - val_loss: 0.6311 - val_accuracy: 0.6637\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.8115 - accuracy: 0.6397 - val_loss: 0.7631 - val_accuracy: 0.6027\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.6933 - accuracy: 0.6425 - val_loss: 0.6300 - val_accuracy: 0.6637\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.6667 - accuracy: 0.6574 - val_loss: 0.6232 - val_accuracy: 0.6653\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.6515 - accuracy: 0.6648 - val_loss: 0.6445 - val_accuracy: 0.6573\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 17s 119ms/step - loss: 0.6504 - accuracy: 0.6616 - val_loss: 0.5953 - val_accuracy: 0.6707\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 16s 116ms/step - loss: 0.6634 - accuracy: 0.6566 - val_loss: 0.5753 - val_accuracy: 0.7167\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.6215 - accuracy: 0.6749 - val_loss: 0.5731 - val_accuracy: 0.7013\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.5995 - accuracy: 0.7065 - val_loss: 0.5255 - val_accuracy: 0.7673\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.7053 - accuracy: 0.7123 - val_loss: 0.6227 - val_accuracy: 0.7133\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.5521 - accuracy: 0.7449 - val_loss: 0.4880 - val_accuracy: 0.7520\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 16s 112ms/step - loss: 0.5243 - accuracy: 0.7432 - val_loss: 0.4838 - val_accuracy: 0.7463\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.5944 - accuracy: 0.7413 - val_loss: 0.3837 - val_accuracy: 0.8120\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.4864 - accuracy: 0.7666 - val_loss: 0.3455 - val_accuracy: 0.8453\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.4414 - accuracy: 0.7866 - val_loss: 0.6355 - val_accuracy: 0.7090\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.4417 - accuracy: 0.7877 - val_loss: 0.3001 - val_accuracy: 0.8603\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.4117 - accuracy: 0.8125 - val_loss: 0.3099 - val_accuracy: 0.8560\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 16s 112ms/step - loss: 0.4144 - accuracy: 0.8072 - val_loss: 0.3016 - val_accuracy: 0.8417\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.3552 - accuracy: 0.8261 - val_loss: 0.2386 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.3413 - accuracy: 0.8359 - val_loss: 0.2822 - val_accuracy: 0.8527\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.3603 - accuracy: 0.8271 - val_loss: 0.9248 - val_accuracy: 0.6847\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 16s 112ms/step - loss: 0.3181 - accuracy: 0.8590 - val_loss: 0.1949 - val_accuracy: 0.9343\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.2951 - accuracy: 0.8651 - val_loss: 0.1661 - val_accuracy: 0.9530\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.3012 - accuracy: 0.8605 - val_loss: 0.1609 - val_accuracy: 0.9467\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 17s 118ms/step - loss: 0.2767 - accuracy: 0.8825 - val_loss: 0.1497 - val_accuracy: 0.9370\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.2399 - accuracy: 0.9055 - val_loss: 0.2540 - val_accuracy: 0.8620\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.2385 - accuracy: 0.9093 - val_loss: 0.1445 - val_accuracy: 0.9407\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.1852 - accuracy: 0.9297 - val_loss: 0.3081 - val_accuracy: 0.8493\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.1723 - accuracy: 0.9292 - val_loss: 0.1409 - val_accuracy: 0.9303\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.1520 - accuracy: 0.9453 - val_loss: 0.4147 - val_accuracy: 0.8033\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.1477 - accuracy: 0.9518 - val_loss: 0.0155 - val_accuracy: 0.9993\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.1313 - accuracy: 0.9552 - val_loss: 0.0227 - val_accuracy: 0.9993\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 0.1008 - accuracy: 0.9658 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.1020 - accuracy: 0.9673 - val_loss: 0.1690 - val_accuracy: 0.9403\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.1005 - accuracy: 0.9698 - val_loss: 0.0209 - val_accuracy: 0.9943\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 16s 116ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 16s 115ms/step - loss: 0.0863 - accuracy: 0.9738 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.7120 - val_accuracy: 0.8277\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.0663 - accuracy: 0.9801 - val_loss: 0.3763 - val_accuracy: 0.9103\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.0720 - accuracy: 0.9798 - val_loss: 0.2701 - val_accuracy: 0.9057\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 17s 117ms/step - loss: 0.1169 - accuracy: 0.9706 - val_loss: 5.1064e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv1D(filters=32, kernel_size=3, input_shape=input_shape,activation='relu'))\n",
    "model4.add(MaxPooling1D(pool_size=2))\n",
    "model4.add(Conv1D(filters=32, kernel_size=10, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling1D(pool_size=2))\n",
    "model4.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model4.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_test, y_test), callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeQa_DI-dYKa",
    "outputId": "2a39d935-a036-41cd-9316-a80f63f2c75f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_02.h/assets\n",
      "INFO:tensorflow:Assets written to: model_02.tflite/assets\n"
     ]
    }
   ],
   "source": [
    "model4.save(\"model_02.h5\")\n",
    "model4.save(\"model_02.h\")\n",
    "model4.save(\"model_02.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTWmOt3KUNzK",
    "outputId": "be213944-dfc8-4029-fc34-45a177d696a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model_12.h/ (stored 0%)\n",
      "  adding: content/model_12.h/variables/ (stored 0%)\n",
      "  adding: content/model_12.h/variables/variables.index (deflated 68%)\n",
      "  adding: content/model_12.h/variables/variables.data-00000-of-00001 (deflated 14%)\n",
      "  adding: content/model_12.h/saved_model.pb (deflated 90%)\n",
      "  adding: content/model_12.h/assets/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/file1.zip /content/model_12.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8c8IbPJuVdKI",
    "outputId": "8e938042-fab2-4127-b682-63cfb92855b4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_94bbb78d-49fa-4860-b78a-92da3bd1f8fc\", \"file1.zip\", 138611)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/file1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "csY4QcrBVdNB",
    "outputId": "eeed6166-7434-4e7e-da8e-27c6881606d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model_13.tflite/ (stored 0%)\n",
      "  adding: content/model_13.tflite/variables/ (stored 0%)\n",
      "  adding: content/model_13.tflite/variables/variables.index (deflated 68%)\n",
      "  adding: content/model_13.tflite/variables/variables.data-00000-of-00001 (deflated 14%)\n",
      "  adding: content/model_13.tflite/saved_model.pb (deflated 89%)\n",
      "  adding: content/model_13.tflite/assets/ (stored 0%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_53dff7c3-bb4c-4cd5-a937-0571eec0c205\", \"file2.zip\", 139865)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!zip -r /content/file2.zip /content/model_13.tflite\n",
    "from google.colab import files\n",
    "files.download(\"/content/file2.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "5Q3sE5zyVdQO",
    "outputId": "1e183c7f-f992-407b-b148-a65f6244ee0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model_02.tflite/ (stored 0%)\n",
      "  adding: content/model_02.tflite/variables/ (stored 0%)\n",
      "  adding: content/model_02.tflite/variables/variables.index (deflated 65%)\n",
      "  adding: content/model_02.tflite/variables/variables.data-00000-of-00001 (deflated 9%)\n",
      "  adding: content/model_02.tflite/saved_model.pb (deflated 89%)\n",
      "  adding: content/model_02.tflite/assets/ (stored 0%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_81c29401-631b-4474-b084-1461bf9bc76a\", \"file3.zip\", 578889)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!zip -r /content/file3.zip /content/model_02.tflite\n",
    "from google.colab import files\n",
    "files.download(\"/content/file3.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "56O380GmXm4D",
    "outputId": "8956485c-cbcd-45c3-8116-321598a0d5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model_02.h/ (stored 0%)\n",
      "  adding: content/model_02.h/variables/ (stored 0%)\n",
      "  adding: content/model_02.h/variables/variables.index (deflated 65%)\n",
      "  adding: content/model_02.h/variables/variables.data-00000-of-00001 (deflated 9%)\n",
      "  adding: content/model_02.h/saved_model.pb (deflated 89%)\n",
      "  adding: content/model_02.h/assets/ (stored 0%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3d82250b-9cfd-4488-ab93-73adb0fca50a\", \"file4.zip\", 577100)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!zip -r /content/file4.zip /content/model_02.h\n",
    "from google.colab import files\n",
    "files.download(\"/content/file4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2bTMTB3ls-Y",
    "outputId": "9aed90b7-6949-4a1e-dc4a-9c7c4e68ad8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 16,805\n",
      "Trainable params: 16,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "modelFromFile1 = load_model('model_01.h5')\n",
    "modelFromFile1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wM9QktLZnQXY"
   },
   "outputs": [],
   "source": [
    "X = df3.iloc[:,0:128]\n",
    "y = df3.iloc[:,128]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwOmPlJink7B",
    "outputId": "cdebc79c-28fe-44d3-ebdc-a1766302630b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.100976\n",
       "1      0.095682\n",
       "2      0.093980\n",
       "3      0.099467\n",
       "4      0.105395\n",
       "         ...   \n",
       "123    0.191098\n",
       "124    0.172757\n",
       "125    0.156305\n",
       "126    0.137103\n",
       "127    0.128521\n",
       "Name: 10, Length: 128, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qMj7YXOqW5k",
    "outputId": "c6c48697-90d6-4d0b-db6f-9bc0166c04e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10097559 0.09568241 0.09398043 0.09946731 0.10539461 0.11751965\n",
      "  0.1282123  0.13945609 0.15910444 0.17420396 0.20359741 0.22089105\n",
      "  0.25227275 0.27670695 0.30702309 0.33491161 0.37174655 0.39266343\n",
      "  0.42795361 0.45906763 0.48984899 0.51901423 0.5549073  0.58375781\n",
      "  0.599911   0.63533343 0.6519587  0.89662823 0.7359912  0.72486344\n",
      "  0.70752824 0.72868095 0.72637905 0.7333887  0.73082993 0.72697547\n",
      "  0.71723193 0.71774294 0.70176078 0.70262081 0.66451529 0.64394977\n",
      "  0.62368859 0.60534569 0.57496407 0.55646626 0.52233289 0.49453366\n",
      "  0.462421   0.4300543  0.40225676 0.37183031 0.33913715 0.30454545\n",
      "  0.27569328 0.2520555  0.22780508 0.20091318 0.18179382 0.15786113\n",
      "  0.14087641 0.12826548 0.22652836 0.12872176 0.11181949 0.09602775\n",
      "  0.09357639 0.09976432 0.10602906 0.11628539 0.12847193 0.14186684\n",
      "  0.15787747 0.18058559 0.20502323 0.22206813 0.24899114 0.28152354\n",
      "  0.30884971 0.40519951 0.44366332 0.47630539 0.52239141 0.55716745\n",
      "  0.59087465 0.63232193 0.66567122 0.6988457  0.72794856 0.76143689\n",
      "  0.78317013 0.81108613 0.83056951 0.84675997 0.86578618 0.87465687\n",
      "  0.88045688 0.8863225  0.88920219 0.88254705 0.87468731 0.86101634\n",
      "  0.84734761 0.83127521 0.80983807 0.79055281 0.76097477 0.73402427\n",
      "  0.69791492 0.66770952 0.62788608 0.59669293 0.55944431 0.5262275\n",
      "  0.48148079 0.44516293 0.41297858 0.37026788 0.33661416 0.30327093\n",
      "  0.27355469 0.2425027  0.21979992 0.1910984  0.17275669 0.15630503\n",
      "  0.13710347 0.12852102]]\n",
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "single_test = X.iloc[10,:]\n",
    "single_test = single_test.values.reshape(1,128)\n",
    "print(single_test)\n",
    "print(single_test.shape)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beF0rYdAmOo0",
    "outputId": "99808fdf-189f-4e04-dd41-e25d2eb7592a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "Time taken was 0.03906655311584473 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(modelFromFile1.predict_classes(single_test))\n",
    "t2 = time.time()\n",
    "print( 'Time taken was {} seconds'.format( t2 - t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_cYpNItl8zk",
    "outputId": "7fc17a91-6410-4179-8548-a799da893966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 126, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 63, 32)            10272     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 31, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 66,997\n",
      "Trainable params: 66,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "modelFromFile2 = load_model('model_02.h5')\n",
    "modelFromFile2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4AfRlfisywf",
    "outputId": "67d9e4cc-a2de-4d76-dbca-78b0e67bd3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "X_train[1].shape\n",
    "single_test1 = x_train[1]\n",
    "single_test1 = single_test1.reshape(1,128)\n",
    "print(single_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWJbexvYtzXW",
    "outputId": "88ee428c-742f-43d1-cfaf-6ead1e58910c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = x_train[0].reshape(1,128,1)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUui2teywvBN",
    "outputId": "8e3723a0-107c-496a-a750-2f6f387d8154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8998, 128, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv_ceNQbm_Gc",
    "outputId": "b7642c58-418a-4b72-e3a3-bafb692e10b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "Time taken was 0.06153512001037598 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(modelFromFile2.predict_classes(i))\n",
    "t2 = time.time()\n",
    "print( 'Time taken was {} seconds'.format( t2 - t1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HoneyWell_03_02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
